"""
ä¸»ç¨‹åº - é›™å›åˆæµç¨‹
å¯¦ç¾ï¼š
1. åˆ¤å®šå›åˆï¼šä¸¦è¡ŒåŸ·è¡Œ RAG æª¢ç´¢ + K/C/R ç¶­åº¦åˆ¤å®šï¼ˆè¿”å›æƒ…å¢ƒç·¨è™Ÿï¼‰
2. æœ€çµ‚å›åˆï¼šå‘Šè¨´ AI ç•¶å‰æƒ…å¢ƒï¼Œçµåˆ RAG + æœ¬é«”è«–ï¼Œç”Ÿæˆæµå¼ç­”æ¡ˆ
"""
import asyncio
import os
import time
from datetime import datetime
from typing import Dict, List, Optional
from pathlib import Path
from openai import OpenAI

from core.vector_store import VectorStore
from core.rag_module import RAGRetriever, RAGCache
from core.scenario_classifier import ScenarioClassifier
from core.ontology_manager import OntologyManager
from core.history_manager import HistoryManager
from core.timer_utils import Timer
from config import Config, get_shared_client


class ResponsesRAGSystem:
    """ä½¿ç”¨ Responses API çš„é›™å›åˆ RAG ç³»çµ±"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–ç³»çµ±
        
        Args:
            api_key: OpenAI API Key
        """
        self.api_key = api_key
        # ä½¿ç”¨å…±äº«çš„ OpenAI client
        self.client = get_shared_client(api_key)
        
        # åˆå§‹åŒ–å„æ¨¡çµ„
        self.vector_store = VectorStore(api_key=api_key)
        self.rag_retriever = RAGRetriever(self.vector_store)
        self.rag_cache = RAGCache()
        self.scenario_classifier = ScenarioClassifier(api_key=api_key)
        self.ontology_manager = OntologyManager()
        self.history_manager = HistoryManager()
        
        # è¨ˆæ™‚å™¨
        self.timer = Timer()
        
        # å°‡è¨ˆæ™‚å™¨æ³¨å…¥åˆ° scenario_classifier
        self.scenario_classifier.set_timer(self.timer)
        
        print("ğŸš€ RAG ç³»çµ±å·²åˆå§‹åŒ–ï¼ˆK, C, R ä¸‰ç¶­åº¦åˆ†é¡ï¼‰")
    
    async def initialize_documents(self, docs_dir: str = None):
        """
        åˆå§‹åŒ–æ–‡ä»¶å‘é‡åŒ–
        
        Args:
            docs_dir: æ–‡ä»¶ç›®éŒ„
        """
        docs_dir = docs_dir or Config.DOCS_DIR
        
        print(f"\nğŸ“š åˆå§‹åŒ–æ–‡ä»¶å‘é‡...")
        self.timer.start_stage("å‘é‡åŒ–")
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰å‘é‡æ–‡ä»¶
        if self.vector_store.load():
            self.timer.stop_stage("å‘é‡åŒ–")
            print("âœ… ä½¿ç”¨å·²å„²å­˜çš„å‘é‡ï¼ˆå¿«é€Ÿå•Ÿå‹•ï¼‰")
            return
        
        # ç¬¬ä¸€æ¬¡å•Ÿå‹•ï¼Œéœ€è¦å‘é‡åŒ–
        print("âš ï¸  é¦–æ¬¡å•Ÿå‹•ï¼Œéœ€è¦èª¿ç”¨ OpenAI API ç”Ÿæˆå‘é‡")
        print("â³ é è¨ˆéœ€è¦ 10-15 ç§’ï¼Œè«‹ç¨å€™...")
        
        # è®€å–ä¸¦å‘é‡åŒ–æ–‡ä»¶
        if not os.path.exists(docs_dir):
            print(f"âš ï¸  æ–‡ä»¶ç›®éŒ„ä¸å­˜åœ¨: {docs_dir}")
            self.timer.stop_stage("å‘é‡åŒ–")
            return
        
        documents = []
        for filename in os.listdir(docs_dir):
            filepath = os.path.join(docs_dir, filename)
            if os.path.isfile(filepath) and filename.endswith('.txt'):
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    documents.append({
                        "id": filename,
                        "content": content,
                        "metadata": {"filename": filename}
                    })
                    print(f"  ğŸ“„ è¼‰å…¥: {filename} ({len(content)} å­—)")
        
        if documents:
            await self.vector_store.batch_add_documents(documents)
            self.vector_store.save()
            self.vector_store.export_to_json()
        
        self.timer.stop_stage("å‘é‡åŒ–")
    
    async def main_thread_rag(self, query: str) -> Dict:
        """
        ä¸»ç·šï¼ˆThread 1ï¼‰ï¼šRAG æª¢ç´¢ï¼ˆä¸ç”Ÿæˆè‰ç¨¿ï¼‰
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            RAG æª¢ç´¢çµæœ
        """
        import time
        t_start = time.perf_counter()
        
        self.timer.start_stage("RAGæª¢ç´¢", thread='A')
        
        # RAG æª¢ç´¢
        retrieved_docs = await self.rag_retriever.retrieve(query, top_k=3)
        context = self.rag_retriever.format_context(retrieved_docs)
        matched_doc_ids = self.rag_retriever.get_matched_doc_ids(retrieved_docs)
        
        # æå–çŸ¥è­˜é»
        knowledge_points = []
        for doc_id in matched_doc_ids:
            if doc_id in Config.KNOWLEDGE_POINTS:
                knowledge_points.append(Config.KNOWLEDGE_POINTS[doc_id])
        
        self.timer.stop_stage("RAGæª¢ç´¢", thread='A')
        
        t_end = time.perf_counter()
        rag_total_time = t_end - t_start
        
        # ç²å– RAG å…§éƒ¨è¨ˆæ™‚
        rag_timing = getattr(self.rag_retriever, '_last_timing', {})
        
        return {
            "context": context,
            "matched_docs": matched_doc_ids,
            "knowledge_points": knowledge_points,
            "retrieved_docs": retrieved_docs,
            "timing": {
                "total": rag_total_time,
                "embedding_api": rag_timing.get("embedding_api", 0),
                "similarity_calc": rag_timing.get("similarity_calc", 0)
            }
        }
    
    async def parallel_dimension_classification(self, query: str, matched_docs: List[str]) -> Dict:
        """
        ä¸¦è¡ŒåŸ·è¡Œ K/C/R ä¸‰ç¶­åº¦åˆ¤å®š
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            matched_docs: RAG åŒ¹é…åˆ°çš„æ–‡æª” ID
            
        Returns:
            æƒ…å¢ƒåˆ¤å®šçµæœ
        """
        # ä½¿ç”¨ ScenarioClassifier é€²è¡Œåˆ†é¡
        result = await self.scenario_classifier.classify(query)
        
        return result
    
    async def final_round_generate(
        self, 
        rag_result: Dict, 
        scenario_result: Dict, 
        query: str
    ) -> str:
        """
        æœ€çµ‚å›åˆï¼šç°¡å–®å‘Šè¨´ AI ç•¶å‰æƒ…å¢ƒï¼Œçµåˆ RAG + æœ¬é«”è«–ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            rag_result: ä¸»ç·šçš„ RAG çµæœ
            scenario_result: åˆ†æ”¯çš„æƒ…å¢ƒåˆ¤å®šçµæœ
            query: ç”¨æˆ¶å•é¡Œ
            
        Returns:
            æœ€çµ‚ç­”æ¡ˆ
        """
        print("\nã€æœ€çµ‚å›åˆã€‘æ•´åˆ RAG + æœ¬é«”è«–ç”Ÿæˆç­”æ¡ˆ...")
        
        # æå–çµæœ
        context = rag_result['context']
        knowledge_points = rag_result['knowledge_points']
        
        scenario_number = scenario_result['scenario_number']
        dimensions = scenario_result['dimensions']
        
        # ç²å–æƒ…å¢ƒæç¤ºè©
        scenario_prompt = scenario_result.get('prompt', '')
        scenario_label = scenario_result.get('label', '')
        
        # è¼‰å…¥æœ¬é«”è«–
        ontology_content = self.ontology_manager.get_ontology_content()
        
        # æ§‹å»ºæœ€çµ‚æç¤ºè©ï¼ˆåŠ å…¥ç•¶å‰æƒ…å¢ƒç·¨è™Ÿ + æ¸¬è©¦èªªæ˜ï¼‰
        final_prompt = f"""
        ã€ç•¶å‰æ˜¯ç¬¬ {scenario_number} ç¨®æƒ…å¢ƒã€‘

        {scenario_prompt}

        ã€RAG æª¢ç´¢åˆ°çš„æ•™æç‰‡æ®µã€‘
        {context}

        ã€çŸ¥è­˜æœ¬é«”è«–ã€‘
        {ontology_content}

        ã€åŒ¹é…çš„çŸ¥è­˜é»ã€‘
        {', '.join(knowledge_points) if knowledge_points else 'ç„¡'}

        ã€ç”¨æˆ¶å•é¡Œã€‘
        {query}

        âš ï¸ æ³¨æ„ï¼šé€™æ˜¯æ¸¬è©¦ç’°å¢ƒï¼Œè«‹å°‡å›ç­”æ§åˆ¶åœ¨ç´„ 100 å­—å·¦å³ï¼Œä»¥ä¾¿æ¸¬è©¦ç³»çµ±éŸ¿æ‡‰æ™‚é–“ã€‚è«‹æ ¹æ“šæ•™æå…§å®¹ç°¡æ½”å›ç­”å•é¡Œã€‚
        """
        
        print(f"ã€æœ€çµ‚å›åˆã€‘æƒ…å¢ƒ {scenario_number}ï¼š{scenario_label}")
        print(f"ã€æœ€çµ‚å›åˆã€‘æç¤ºï¼š{scenario_prompt}")
        
        # ä½¿ç”¨ Responses API ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆï¼ˆæµå¼ï¼‰
        response = self.client.chat.completions.create(
            model=Config.LLM_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çŸ¥è­˜åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": final_prompt}
            ],
            temperature=Config.LLM_TEMPERATURE,
            max_tokens=Config.LLM_FINAL_MAX_TOKENS,  # ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§ token æ•¸
            stream=True
        )
        
        print("\nğŸ’¬ ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆï¼ˆæµå¼è¼¸å‡ºï¼‰...")
        print("-" * 60)
        
        final_answer = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                final_answer += content
        
        print("\n" + "-" * 60)
        
        return final_answer
    
    async def process_query(self, query: str) -> Dict:
        """
        è™•ç†æŸ¥è©¢ï¼ˆ3 å€‹ç¨ç«‹ä¸¦è¡ŒåŸ·è¡Œç·’ + æœ€çµ‚ç”Ÿæˆï¼‰
        
        ç¬¬ä¸€å›åˆï¼šä¸¦è¡ŒåŸ·è¡Œ 3 å€‹ API
          - Thread 1: RAG Embedding
          - Thread 2: C å€¼æª¢æ¸¬
          - Thread 3: çŸ¥è­˜é»æª¢æ¸¬
        ç¬¬äºŒå›åˆï¼šæ•´åˆçµæœï¼Œç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            è™•ç†çµæœ
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“¥ æ”¶åˆ°æŸ¥è©¢: {query}")
        print(f"{'='*70}")
        
        # ç¬¬ä¸€å›åˆï¼šä¸¦è¡ŒåŸ·è¡Œ 3 å€‹ç¨ç«‹ API
        self.timer.start_stage("ä¸¦è¡Œè™•ç†")
        
        import time
        
        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        t_parallel_start = time.perf_counter()
        
        # 3 å€‹ç¨ç«‹çš„åŸ·è¡Œç·’
        rag_task = self.main_thread_rag(query)  # Thread 1: RAG
        
        t_c_start = time.perf_counter()
        c_task = self.scenario_classifier.dimension_classifier.correctness_detector.detect(query)  # Thread 2: Cå€¼
        
        t_k_start = time.perf_counter()
        knowledge_task = self.scenario_classifier.dimension_classifier.knowledge_detector.detect(query)  # Thread 3: çŸ¥è­˜é»
        
        # ç­‰å¾… 3 å€‹ä»»å‹™éƒ½å®Œæˆ
        rag_result, c_value, knowledge_points = await asyncio.gather(
            rag_task,
            c_task,
            knowledge_task
        )
        
        t_parallel_end = time.perf_counter()
        parallel_total_time = t_parallel_end - t_parallel_start
        
        # æœ¬åœ°è¨ˆç®— K å€¼å’Œ R å€¼ï¼ˆä¸éœ€è¦ APIï¼‰
        t_local_start = time.perf_counter()
        k_value = self.scenario_classifier.dimension_classifier.knowledge_detector.calculate_k_value(knowledge_points)
        r_value = self.scenario_classifier.dimension_classifier.repetition_checker.check_and_update(knowledge_points)
        
        # è¨ˆç®—æƒ…å¢ƒç·¨è™Ÿ
        scenario_number = self.scenario_classifier.dimension_classifier.scenario_calculator.calculate(k_value, c_value, r_value)
        t_local_end = time.perf_counter()
        local_calc_time = t_local_end - t_local_start
        
        # è¨˜éŒ„æƒ…å¢ƒè¨ˆç®—å®Œæˆæ™‚é–“é»
        t_scenario_calc_done = time.perf_counter()
        
        # æ‰“å°ç¶­åº¦åˆ†é¡çµæœ
        print(f"\nğŸ” ç¶­åº¦åˆ†é¡çµæœï¼š")
        print(f"  K (çŸ¥è­˜é»æ•¸é‡): {k_value} ({['é›¶å€‹', 'ä¸€å€‹', 'å¤šå€‹'][k_value]})")
        print(f"  C (æ­£ç¢ºæ€§): {c_value} ({['æ­£ç¢º', 'ä¸æ­£ç¢º'][c_value]})")
        print(f"  R (é‡è¤‡æ€§): {r_value} ({['æ­£å¸¸', 'é‡è¤‡'][r_value]})")
        print(f"  çŸ¥è­˜é»: {knowledge_points if knowledge_points else 'ç„¡'}")
        print(f"âœ… è¨ˆç®—å¾—å‡ºæƒ…å¢ƒç·¨è™Ÿï¼š{scenario_number}")
        
        # ç²å–æƒ…å¢ƒè©³ç´°ä¿¡æ¯
        scenario = self.scenario_classifier.get_scenario_by_number(scenario_number)
        
        # æ§‹å»º scenario_result
        scenario_result = {
            "scenario_number": scenario_number,
            "dimensions": {
                "K": k_value,
                "C": c_value,
                "R": r_value
            },
            "knowledge_points": knowledge_points,
            "label": scenario.get('label', '') if scenario else '',
            "role": scenario.get('role', '') if scenario else '',
            "prompt": scenario.get('prompt', '') if scenario else ''
        }
        
        # è¨˜éŒ„æ•´åˆæº–å‚™å®Œæˆæ™‚é–“
        t_integration_done = time.perf_counter()
        integration_time = t_integration_done - t_scenario_calc_done
        
        self.timer.stop_stage("ä¸¦è¡Œè™•ç†")
        
        # æ”¶é›†æ‰€æœ‰è¨ˆæ™‚ä¿¡æ¯
        rag_timing = rag_result.get("timing", {})
        c_timing = getattr(self.scenario_classifier.dimension_classifier.correctness_detector, '_last_timing', 0)
        k_timing = getattr(self.scenario_classifier.dimension_classifier.knowledge_detector, '_last_timing', 0)
        
        # ç¬¬äºŒå›åˆï¼šç”Ÿæˆç­”æ¡ˆ
        self.timer.start_stage("æœ€çµ‚å›åˆç”Ÿæˆ")
        t_final_start = time.perf_counter()
        
        final_answer = await self.final_round_generate(rag_result, scenario_result, query)
        
        t_final_end = time.perf_counter()
        final_generation_time = t_final_end - t_final_start
        
        self.timer.stop_stage("æœ€çµ‚å›åˆç”Ÿæˆ")
        self.timer.stop_stage("ç¸½æµç¨‹")
        
        # æ‰“å°è©³ç´°è¨ˆæ™‚å ±å‘Šï¼ˆåŒ…å«ä¸¦è¡ŒåŸ·è¡Œè©³æƒ…ï¼‰
        print(f"\n{'='*70}")
        print(f"â±ï¸  è©³ç´°æ™‚é–“åˆ†æå ±å‘Šï¼ˆ3 å€‹ä¸¦è¡ŒåŸ·è¡Œç·’ï¼‰")
        print(f"{'='*70}\n")
        
        print(f"ã€ä¸¦è¡ŒåŸ·è¡Œè©³æƒ…ã€‘")
        print(f"  Thread 1 - RAG æª¢ç´¢:")
        print(f"    â”œâ”€ Embedding API èª¿ç”¨: {rag_timing.get('embedding_api', 0):.3f}s")
        print(f"    â”œâ”€ ç›¸ä¼¼åº¦è¨ˆç®—: {rag_timing.get('similarity_calc', 0):.3f}s")
        print(f"    â””â”€ ç¸½è€—æ™‚: {rag_timing.get('total', 0):.3f}s")
        print(f"")
        print(f"  Thread 2 - C å€¼æª¢æ¸¬:")
        print(f"    â””â”€ API èª¿ç”¨è€—æ™‚: {c_timing:.3f}s")
        print(f"")
        print(f"  Thread 3 - çŸ¥è­˜é»æª¢æ¸¬:")
        print(f"    â””â”€ API èª¿ç”¨è€—æ™‚: {k_timing:.3f}s")
        print(f"")
        print(f"  æœ¬åœ°è¨ˆç®— (K/R å€¼):")
        print(f"    â””â”€ è¨ˆç®—è€—æ™‚: {local_calc_time:.6f}s")
        print(f"")
        print(f"  ä¸¦è¡ŒåŸ·è¡Œç¸½æ™‚é–“: {parallel_total_time:.3f}s")
        print(f"  ç†è«–æœ€å¤§æ™‚é–“: {max(rag_timing.get('total', 0), c_timing, k_timing):.3f}s")
        print(f"  ä¸¦è¡Œæ•ˆç‡: {(1 - parallel_total_time / (rag_timing.get('total', 0) + c_timing + k_timing)) * 100:.1f}%")
        print(f"")
        print(f"ã€å¾Œè™•ç†éšæ®µã€‘")
        print(f"  æƒ…å¢ƒè¨ˆç®— + çµæœæ•´åˆ: {integration_time:.3f}s")
        print(f"  æœ€çµ‚ç­”æ¡ˆç”Ÿæˆ: {final_generation_time:.3f}s")
        print(f"  å¾Œè™•ç†ç¸½æ™‚é–“: {integration_time + final_generation_time:.3f}s")
        print(f"\n{'='*70}\n")
        
        # èˆŠç‰ˆæ™‚é–“å ±å‘Šå·²ç§»é™¤ï¼Œåƒ…ä¿ç•™ä¸Šæ–¹æ–°ç‰ˆã€Œè©³ç´°æ™‚é–“åˆ†æå ±å‘Šï¼ˆ3 å€‹ä¸¦è¡ŒåŸ·è¡Œç·’ï¼‰ã€
        
        # è¨˜éŒ„åˆ°æ­·å²ï¼ˆç°¡åŒ–ç‰ˆï¼Œåªè¨˜éŒ„åŸºæœ¬ä¿¡æ¯ï¼‰
        dimensions_dict = {
            "K": scenario_result['dimensions']['K'],
            "C": scenario_result['dimensions']['C'],
            "R": scenario_result['dimensions']['R']
        }
        
        self.history_manager.add_query(
            query,
            rag_result['matched_docs'],
            dimensions_dict,
            scenario_result.get('knowledge_points', [])
        )
        
        # ============ è¿”å›çµæœ ============
        result = {
            "query": query,
            "final_answer": final_answer,
            "scenario_number": scenario_result['scenario_number'],
            "scenario_label": scenario_result.get('label', ''),
            "scenario_role": scenario_result.get('role', ''),
            "scenario_prompt": scenario_result.get('prompt', ''),
            "dimensions": scenario_result['dimensions'],
            "matched_docs": rag_result['matched_docs'],
            "knowledge_points": rag_result['knowledge_points'],
            "time_report": self.timer.get_report().to_dict()
        }
        
        return result
    
    def print_summary(self, result: Dict):
        """æ‰“å°çµæœæ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸ“Š RAG ç³»çµ±è™•ç†çµæœæ‘˜è¦")
        print("="*70)
        print(f"æŸ¥è©¢ï¼š{result['query']}")
        print(f"\nğŸ¯ æƒ…å¢ƒåˆ¤å®šï¼šç¬¬ {result['scenario_number']} ç¨®æƒ…å¢ƒ")
        print(f"   æ¨™ç±¤ï¼š{result['scenario_label']}")
        print(f"   è§’è‰²ï¼š{result['scenario_role']}")
        print(f"\nğŸ“ ä¸‰ç¶­åº¦åˆ†æï¼š")
        k_map = {0: "é›¶å€‹", 1: "ä¸€å€‹", 2: "å¤šå€‹"}
        c_map = {0: "æ­£ç¢º", 1: "ä¸æ­£ç¢º"}
        r_map = {0: "æ­£å¸¸", 1: "é‡è¤‡"}
        dims = result['dimensions']
        print(f"   K (çŸ¥è­˜é»æ•¸é‡): {k_map.get(dims['K'], dims['K'])}")
        print(f"   C (æ­£ç¢ºæ€§): {c_map.get(dims['C'], dims['C'])}")
        print(f"   R (é‡è¤‡æ€§): {r_map.get(dims['R'], dims['R'])}")
        print(f"\nğŸ“š åŒ¹é…çŸ¥è­˜é»ï¼š{', '.join(result['knowledge_points']) if result['knowledge_points'] else 'ç„¡'}")
        print(f"\nâ±ï¸  åŸ·è¡Œæ™‚é–“åˆ†æï¼š")
        time_report = result['time_report']
        
        # ä¸»æµç¨‹æ™‚é–“
        if 'stages' in time_report:
            print("  â”Œâ”€ ã€ä¸»æµç¨‹ - ç¸½é«”æ™‚é–“ã€‘")
            for stage, duration in time_report['stages'].items():
                print(f"  â”‚   {stage:30s}: {duration:6.3f}s")
        
        # Thread A æ™‚é–“ï¼ˆRAG æª¢ç´¢ï¼‰
        if 'thread_a' in time_report:
            print(f"  â”œâ”€ ã€{time_report['thread_a']['thread_name']}ã€‘")
            for stage, duration in time_report['thread_a']['stages'].items():
                print(f"  â”‚   {stage:30s}: {duration:6.3f}s")
            print(f"  â”‚   {'â”€' * 40}")
            print(f"  â”‚   {'ä¸»ç·šå°è¨ˆ':30s}: {time_report['thread_a']['total_time']:6.3f}s")
        
        # Thread B æ™‚é–“ï¼ˆResponses API æƒ…å¢ƒåˆ¤å®šï¼‰
        if 'thread_b' in time_report:
            print(f"  â””â”€ ã€{time_report['thread_b']['thread_name']}ã€‘")
            for stage, duration in time_report['thread_b']['stages'].items():
                print(f"      {stage:30s}: {duration:6.3f}s")
            print(f"      {'â”€' * 40}")
            print(f"      {'æ”¯ç·šå°è¨ˆ':30s}: {time_report['thread_b']['total_time']:6.3f}s")
        
        print(f"\n  ğŸ¯ ç¸½è¨ˆæ™‚é–“: {time_report['total_time']:.3f}s")
        print("="*70)


async def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "="*70)
    print("ğŸš€ RAG æ•™å­¸å•ç­”ç³»çµ± (K/C/R ä¸‰ç¶­åº¦åˆ†é¡)")
    print("="*70)
    
    # åˆå§‹åŒ–ç³»çµ±
    system = ResponsesRAGSystem()
    
    # åˆå§‹åŒ–æ–‡ä»¶
    await system.initialize_documents()
    
    # æ¸¬è©¦æŸ¥è©¢
    test_queries = [
        "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
        "æ©Ÿå™¨å­¸ç¿’å’Œæ·±åº¦å­¸ç¿’æœ‰ä»€éº¼å€åˆ¥ï¼Ÿ"
    ]
    
    for query in test_queries:
        result = await system.process_query(query)
        system.print_summary(result)
        print("\n")


if __name__ == "__main__":
    asyncio.run(main())
