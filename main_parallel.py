"""
ä¸»ç¨‹åº - ä¸¦è¡Œè™•ç†ç‰ˆæœ¬
æ”¯æŒå¤šç·šç¨‹ä¸¦è¡Œåˆ†æå››å‘åº¦
"""
import asyncio
import json
import os
from datetime import datetime
from typing import Dict, List, Optional
from openai import OpenAI

from vector_store import VectorStore
from rag_module import RAGRetriever, RAGCache
from scenario_module import DimensionClassifier
from scenario_matcher import ScenarioMatcher
from timer_utils import Timer
from config import Config


class ParallelRAGSystem:
    """ä¸¦è¡Œè™•ç†çš„ RAG æµå¼ç³»çµ±"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–ç³»çµ±
        
        Args:
            api_key: OpenAI API Key
        """
        self.api_key = api_key
        self.client = OpenAI(api_key=api_key) if api_key else OpenAI()
        
        # åˆå§‹åŒ–å„æ¨¡çµ„
        self.vector_store = VectorStore(api_key=api_key)
        self.rag_retriever = RAGRetriever(self.vector_store)
        self.rag_cache = RAGCache()
        self.dimension_classifier = DimensionClassifier(api_key=api_key)
        self.scenario_matcher = ScenarioMatcher()
        
        # è¨ˆæ™‚å™¨
        self.timer = Timer()
        
        print("ğŸš€ ä¸¦è¡Œ RAG æµå¼ç³»çµ±å·²åˆå§‹åŒ–")
    
    async def initialize_documents(self, docs_dir: str = None):
        """
        åˆå§‹åŒ–æ–‡ä»¶å‘é‡åŒ–
        
        Args:
            docs_dir: æ–‡ä»¶ç›®éŒ„
        """
        docs_dir = docs_dir or Config.DOCS_DIR
        
        print(f"\nğŸ“š é–‹å§‹å‘é‡åŒ–æ–‡ä»¶...")
        self.timer.start_stage("å‘é‡åŒ–")
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰å‘é‡æ–‡ä»¶
        if self.vector_store.load():
            self.timer.stop_stage("å‘é‡åŒ–")
            print("âœ… ä½¿ç”¨å·²å„²å­˜çš„å‘é‡")
            return
        
        # è®€å–ä¸¦å‘é‡åŒ–æ–‡ä»¶
        if not os.path.exists(docs_dir):
            print(f"âš ï¸  æ–‡ä»¶ç›®éŒ„ä¸å­˜åœ¨: {docs_dir}")
            self.timer.stop_stage("å‘é‡åŒ–")
            return
        
        documents = []
        for filename in os.listdir(docs_dir):
            filepath = os.path.join(docs_dir, filename)
            if os.path.isfile(filepath) and filename.endswith('.txt'):
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    documents.append({
                        "id": filename,
                        "content": content,
                        "metadata": {"filename": filename}
                    })
                    print(f"  ğŸ“„ è¼‰å…¥: {filename} ({len(content)} å­—)")
        
        if documents:
            await self.vector_store.batch_add_documents(documents)
            self.vector_store.save()
            self.vector_store.export_to_json()
        
        self.timer.stop_stage("å‘é‡åŒ–")
    
    async def rag_retrieval(self, query: str) -> Dict:
        """
        RAG æª¢ç´¢ï¼ˆç·šç¨‹ 1ï¼‰
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            æª¢ç´¢çµæœ
        """
        retrieved_docs = await self.rag_retriever.retrieve(query, top_k=3)
        context = self.rag_retriever.format_context(retrieved_docs)
        matched_doc_ids = self.rag_retriever.get_matched_doc_ids(retrieved_docs)
        
        # æå–çŸ¥è­˜é»
        knowledge_points = []
        for doc_id in matched_doc_ids:
            if doc_id in Config.KNOWLEDGE_POINTS:
                knowledge_points.append(Config.KNOWLEDGE_POINTS[doc_id])
        
        return {
            "context": context,
            "matched_docs": matched_doc_ids,
            "knowledge_points": knowledge_points,
            "retrieved_docs": retrieved_docs
        }
    
    async def analyze_d2(self, query: str) -> str:
        """
        D2 åˆ†æï¼šè¡¨é”éŒ¯èª¤ï¼ˆç·šç¨‹ 2ï¼‰
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            D2 çµæœ
        """
        return await self.dimension_classifier._classify_d2(query)
    
    async def analyze_d3(self, query: str) -> str:
        """
        D3 åˆ†æï¼šè¡¨é”è©³ç´°åº¦ï¼ˆç·šç¨‹ 3ï¼‰
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            D3 çµæœ
        """
        return await self.dimension_classifier._classify_d3(query)
    
    async def analyze_d4(self, query: str, knowledge_points: List[str]) -> str:
        """
        D4 åˆ†æï¼šé‡è¤‡è©¢å•ï¼ˆç·šç¨‹ 4ï¼‰
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            knowledge_points: çŸ¥è­˜é»åˆ—è¡¨
            
        Returns:
            D4 çµæœ
        """
        return await self.dimension_classifier._classify_d4(query, knowledge_points)
    
    def analyze_d1(self, knowledge_points: List[str]) -> str:
        """
        D1 åˆ†æï¼šçŸ¥è­˜é»æ•¸é‡ï¼ˆéœ€è¦ RAG çµæœï¼‰
        
        Args:
            knowledge_points: çŸ¥è­˜é»åˆ—è¡¨
            
        Returns:
            D1 çµæœ
        """
        return self.dimension_classifier._classify_d1(knowledge_points)
    
    async def process_query_parallel(self, query: str) -> Dict:
        """
        ä¸¦è¡Œè™•ç†æŸ¥è©¢
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            å®Œæ•´çµæœ
        """
        print("\n" + "="*60)
        print(f"ğŸ” è™•ç†æŸ¥è©¢: {query}")
        print("="*60)
        
        # é‡ç½®è¨ˆæ™‚å™¨
        self.timer = Timer()
        self.timer.start_stage("ç¸½æµç¨‹")
        
        # ============ éšæ®µ 1ï¼šä¸¦è¡Œåˆ†æ ============
        print("\nğŸš€ éšæ®µ 1ï¼šå•Ÿå‹•ä¸¦è¡Œåˆ†æ...")
        self.timer.start_stage("ä¸¦è¡Œåˆ†æ")
        
        # å•Ÿå‹•ä¸¦è¡Œä»»å‹™
        # æ³¨æ„ï¼šD2, D3 å¯ä»¥ç«‹å³é–‹å§‹ï¼ŒD4 éœ€è¦çŸ¥è­˜é»ä½†å¯ä»¥å…ˆæº–å‚™
        rag_task = self.rag_retrieval(query)
        d2_task = self.analyze_d2(query)
        d3_task = self.analyze_d3(query)
        
        # ç­‰å¾… RAG å’Œ D2, D3 å®Œæˆ
        rag_result, d2_result, d3_result = await asyncio.gather(
            rag_task,
            d2_task,
            d3_task
        )
        
        print(f"  âœ… RAG æª¢ç´¢å®Œæˆï¼šæ‰¾åˆ° {len(rag_result['matched_docs'])} å€‹æ–‡ä»¶")
        print(f"  âœ… D2 åˆ†æå®Œæˆï¼š{d2_result}")
        print(f"  âœ… D3 åˆ†æå®Œæˆï¼š{d3_result}")
        
        # D1 éœ€è¦ RAG çµæœ
        d1_result = self.analyze_d1(rag_result['knowledge_points'])
        print(f"  âœ… D1 åˆ†æå®Œæˆï¼š{d1_result}")
        
        # D4 éœ€è¦çŸ¥è­˜é»
        d4_result = await self.analyze_d4(query, rag_result['knowledge_points'])
        print(f"  âœ… D4 åˆ†æå®Œæˆï¼š{d4_result}")
        
        self.timer.stop_stage("ä¸¦è¡Œåˆ†æ")
        
        # ============ éšæ®µ 2ï¼šæƒ…å¢ƒåˆ¤å®š ============
        print("\nğŸ¯ éšæ®µ 2ï¼šåˆ¤å®šæƒ…å¢ƒ...")
        self.timer.start_stage("æƒ…å¢ƒåˆ¤å®š")
        
        dimensions = {
            "D1": d1_result,
            "D2": d2_result,
            "D3": d3_result,
            "D4": d4_result
        }
        
        scenario = self.scenario_matcher.match_scenario(dimensions)
        
        if scenario:
            scenario_number = scenario['scenario_number']
            print(f"  âœ… åˆ¤å®šç‚ºç¬¬ {scenario_number} å€‹æƒ…å¢ƒï¼š{scenario['name']}")
        else:
            print(f"  âš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„æƒ…å¢ƒï¼Œä½¿ç”¨é»˜èªè™•ç†")
            scenario = self._get_default_scenario()
            scenario_number = 0
        
        self.timer.stop_stage("æƒ…å¢ƒåˆ¤å®š")
        
        # ============ éšæ®µ 3ï¼šåˆä½µåˆ°ä¸»ç·šç¨‹ ============
        print("\nğŸ”— éšæ®µ 3ï¼šåˆä½µæ•¸æ“šåˆ°ä¸»ç·šç¨‹...")
        self.timer.start_stage("æ•¸æ“šåˆä½µ")
        
        merged_context = self.merge_to_main_thread(
            rag_result=rag_result,
            dimensions=dimensions,
            scenario_data=scenario,
            query=query
        )
        
        print(f"  âœ… æ•¸æ“šåˆä½µå®Œæˆ")
        print(f"     - RAG ä¸Šä¸‹æ–‡ï¼š{len(merged_context['rag_context'])} å­—")
        print(f"     - çŸ¥è­˜é»ï¼š{', '.join(merged_context['knowledge_points'])}")
        print(f"     - æƒ…å¢ƒæ•¸æ“šï¼šå·²è¼‰å…¥")
        
        self.timer.stop_stage("æ•¸æ“šåˆä½µ")
        
        # ============ éšæ®µ 4ï¼šä¸»ç·šç¨‹è™•ç† ============
        print("\nâš™ï¸  éšæ®µ 4ï¼šä¸»ç·šç¨‹è™•ç†...")
        self.timer.start_stage("ä¸»ç·šç¨‹è™•ç†")
        
        final_answer = await self.main_thread_process(merged_context)
        
        self.timer.stop_stage("ä¸»ç·šç¨‹è™•ç†")
        
        # è¨˜éŒ„åˆ°æ­·å²
        self.dimension_classifier.history_manager.add_query(
            query,
            rag_result['matched_docs'],
            dimensions
        )
        
        self.timer.stop_stage("ç¸½æµç¨‹")
        
        # ============ è¿”å›çµæœ ============
        result = {
            "query": query,
            "final_answer": final_answer,
            "scenario_number": scenario_number,
            "scenario_name": scenario['name'],
            "dimensions": dimensions,
            "dimension_details": self.dimension_classifier.get_dimension_details(dimensions),
            "matched_docs": rag_result['matched_docs'],
            "knowledge_points": rag_result['knowledge_points'],
            "time_report": self.timer.get_report()
        }
        
        return result
    
    def merge_to_main_thread(
        self,
        rag_result: Dict,
        dimensions: Dict,
        scenario_data: Dict,
        query: str
    ) -> Dict:
        """
        å°‡æ‰€æœ‰æ•¸æ“šåˆä½µåˆ°ä¸»ç·šç¨‹
        
        Args:
            rag_result: RAG æª¢ç´¢çµæœ
            dimensions: å››å‘åº¦åˆ†æçµæœ
            scenario_data: æƒ…å¢ƒ JSON æ•¸æ“š
            query: ç”¨æˆ¶å•é¡Œ
            
        Returns:
            åˆä½µå¾Œçš„ä¸Šä¸‹æ–‡
        """
        merged = {
            "query": query,
            "rag_context": rag_result['context'],
            "knowledge_points": rag_result['knowledge_points'],
            "matched_docs": rag_result['matched_docs'],
            "dimensions": dimensions,
            "scenario": scenario_data,
            "response_strategy": scenario_data.get('response_strategy', {}),
            "prompt_template": scenario_data.get('prompt_template', ''),
            "timestamp": datetime.now().isoformat()
        }
        
        # å¦‚æœæ¶‰åŠå¤šå€‹çŸ¥è­˜é»ï¼Œæ·»åŠ é—œè¯ä¿¡æ¯
        if dimensions['D1'] == "å¤šå€‹":
            relations = self.scenario_matcher._get_knowledge_relations_text(
                rag_result['knowledge_points']
            )
            merged['knowledge_relations'] = relations
        
        return merged
    
    async def main_thread_process(self, context: Dict) -> str:
        """
        ä¸»ç·šç¨‹è™•ç†
        
        Args:
            context: åˆä½µå¾Œçš„å®Œæ•´ä¸Šä¸‹æ–‡
            
        Returns:
            æœ€çµ‚ç­”æ¡ˆ
        """
        # æ§‹å»ºæç¤ºè©
        prompt = self.build_prompt_from_context(context)
        
        # èª¿ç”¨ LLM ç”Ÿæˆ
        print("\nğŸ’¬ ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ...")
        print("-" * 50)
        
        response = self.client.chat.completions.create(
            model=Config.LLM_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=Config.LLM_TEMPERATURE,
            max_tokens=Config.LLM_FINAL_MAX_TOKENS,
            stream=True
        )
        
        final_answer = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                final_answer += content
        
        print("\n" + "-" * 50)
        
        return final_answer
    
    def build_prompt_from_context(self, context: Dict) -> str:
        """
        æ ¹æ“šåˆä½µçš„ä¸Šä¸‹æ–‡æ§‹å»ºæç¤ºè©
        
        Args:
            context: å®Œæ•´ä¸Šä¸‹æ–‡
            
        Returns:
            æç¤ºè©
        """
        scenario = context['scenario']
        strategy = context.get('response_strategy', {})
        
        prompt_parts = []
        
        # æƒ…å¢ƒä¿¡æ¯
        prompt_parts.append(f"ã€æƒ…å¢ƒã€‘ç¬¬ {scenario.get('scenario_number', 0)} å€‹æƒ…å¢ƒ")
        prompt_parts.append(f"æƒ…å¢ƒåç¨±ï¼š{scenario.get('name', 'æœªçŸ¥')}")
        prompt_parts.append(f"æƒ…å¢ƒæè¿°ï¼š{scenario.get('description', '')}")
        
        # å›ç­”ç­–ç•¥
        if strategy:
            prompt_parts.append(f"\nã€å›ç­”ç­–ç•¥ã€‘")
            prompt_parts.append(f"èªæ°£ï¼š{strategy.get('tone', 'å‹å¥½ã€å°ˆæ¥­')}")
            prompt_parts.append(f"é•·åº¦ï¼š{strategy.get('length', 'é©ä¸­')}")
            if 'structure' in strategy:
                prompt_parts.append(f"çµæ§‹è¦é»ï¼š{', '.join(strategy['structure'])}")
            if 'emphasis' in strategy:
                prompt_parts.append(f"å¼·èª¿é‡é»ï¼š{', '.join(strategy['emphasis'])}")
        
        # RAG æª¢ç´¢å…§å®¹
        prompt_parts.append(f"\nã€æª¢ç´¢åˆ°çš„æ•™æå…§å®¹ã€‘")
        prompt_parts.append(context['rag_context'])
        
        # çŸ¥è­˜é»é—œè¯
        if 'knowledge_relations' in context:
            prompt_parts.append(f"\nã€çŸ¥è­˜é»é—œè¯ã€‘")
            prompt_parts.append(context['knowledge_relations'])
        
        # ç”¨æˆ¶å•é¡Œ
        prompt_parts.append(f"\nã€ç”¨æˆ¶å•é¡Œã€‘")
        prompt_parts.append(context['query'])
        
        # æƒ…å¢ƒçš„æç¤ºè©æ¨¡æ¿
        if context.get('prompt_template'):
            prompt_parts.append(f"\nã€å…·é«”æŒ‡å¼•ã€‘")
            prompt_parts.append(context['prompt_template'])
        
        prompt_parts.append("\nè«‹æ ¹æ“šä»¥ä¸Šæƒ…å¢ƒå’Œå…§å®¹ï¼Œç”Ÿæˆé©ç•¶çš„å›ç­”ï¼š")
        
        return "\n".join(prompt_parts)
    
    def _get_default_scenario(self) -> Dict:
        """ç²å–é»˜èªæƒ…å¢ƒ"""
        return {
            "id": "default",
            "scenario_number": 0,
            "name": "é»˜èªæƒ…å¢ƒ",
            "description": "æœªåŒ¹é…åˆ°ç‰¹å®šæƒ…å¢ƒï¼Œä½¿ç”¨é»˜èªè™•ç†",
            "response_strategy": {
                "tone": "å‹å¥½ã€å°ˆæ¥­",
                "structure": ["ç›´æ¥å›ç­”å•é¡Œ"],
                "emphasis": ["æä¾›æº–ç¢ºä¿¡æ¯"],
                "length": "é©ä¸­"
            }
        }
    
    def print_summary(self, result: Dict):
        """æ‰“å°çµæœæ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š è™•ç†çµæœæ‘˜è¦")
        print("="*60)
        print(f"æŸ¥è©¢ï¼š{result['query']}")
        print(f"\næƒ…å¢ƒï¼šç¬¬ {result['scenario_number']} å€‹ - {result['scenario_name']}")
        print(f"\nå››å‘åº¦ï¼š")
        for dim, value in result['dimensions'].items():
            detail = result['dimension_details'][dim]
            print(f"  {dim} ({detail['name']}): {value}")
        print(f"\nçŸ¥è­˜é»ï¼š{', '.join(result['knowledge_points']) if result['knowledge_points'] else 'ç„¡'}")
        print(f"\næ™‚é–“å ±å‘Šï¼š")
        for stage, duration in result['time_report']['stages'].items():
            print(f"  {stage}: {duration:.3f}s")
        print(f"  ç¸½è¨ˆ: {result['time_report']['total_time']:.3f}s")
        print("="*60)


async def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "="*60)
    print("ğŸš€ ä¸¦è¡Œ RAG æµå¼ç³»çµ±")
    print("="*60)
    
    # åˆå§‹åŒ–ç³»çµ±
    system = ParallelRAGSystem()
    
    # åˆå§‹åŒ–æ–‡ä»¶
    await system.initialize_documents()
    
    # æ¸¬è©¦æŸ¥è©¢
    test_queries = [
        "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
        "æ©Ÿå™¨å­¸ç¿’å’Œæ·±åº¦å­¸ç¿’æœ‰ä»€éº¼å€åˆ¥ï¼Ÿè«‹è©³ç´°èªªæ˜ã€‚",
    ]
    
    for query in test_queries:
        result = await system.process_query_parallel(query)
        system.print_summary(result)
        print("\n")


if __name__ == "__main__":
    asyncio.run(main())
