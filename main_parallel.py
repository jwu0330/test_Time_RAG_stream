"""
ä¸»ç¨‹åº - ä½¿ç”¨ Responses API çš„é›™å›åˆæµç¨‹
å¯¦ç¾ï¼š
1. åˆ¤å®šå›åˆï¼šä¸¦è¡ŒåŸ·è¡Œ RAG æª¢ç´¢ + Responses API function callï¼ˆè¿”å›æƒ…å¢ƒç·¨è™Ÿï¼‰
2. æœ€çµ‚å›åˆï¼šå‘Šè¨´ AI ç•¶å‰æƒ…å¢ƒï¼Œçµåˆ RAG + æœ¬é«”è«–ï¼Œç”Ÿæˆæµå¼ç­”æ¡ˆ
"""
import asyncio
import os
import time
from datetime import datetime
from typing import Dict, List, Optional
from pathlib import Path
from openai import OpenAI

from core.vector_store import VectorStore
from core.rag_module import RAGRetriever, RAGCache
from core.scenario_classifier import ScenarioClassifier
from core.ontology_manager import OntologyManager
from core.history_manager import HistoryManager
from core.timer_utils import Timer
from config import Config


class ResponsesRAGSystem:
    """ä½¿ç”¨ Responses API çš„é›™å›åˆ RAG ç³»çµ±"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–ç³»çµ±
        
        Args:
            api_key: OpenAI API Key
        """
        self.api_key = api_key
        self.client = OpenAI(api_key=api_key) if api_key else OpenAI()
        
        # åˆå§‹åŒ–å„æ¨¡çµ„
        self.vector_store = VectorStore(api_key=api_key)
        self.rag_retriever = RAGRetriever(self.vector_store)
        self.rag_cache = RAGCache()
        self.scenario_classifier = ScenarioClassifier(api_key=api_key)
        self.ontology_manager = OntologyManager()
        self.history_manager = HistoryManager()
        
        # è¨ˆæ™‚å™¨
        self.timer = Timer()
        
        # å°‡è¨ˆæ™‚å™¨æ³¨å…¥åˆ° scenario_classifier
        self.scenario_classifier.set_timer(self.timer)
        
        print("ğŸš€ Responses API é›™å›åˆ RAG ç³»çµ±å·²åˆå§‹åŒ–ï¼ˆäº”å€‹ä¸¦è¡Œåˆ†æ”¯ï¼‰")
    
    async def initialize_documents(self, docs_dir: str = None):
        """
        åˆå§‹åŒ–æ–‡ä»¶å‘é‡åŒ–
        
        Args:
            docs_dir: æ–‡ä»¶ç›®éŒ„
        """
        docs_dir = docs_dir or Config.DOCS_DIR
        
        print(f"\nğŸ“š åˆå§‹åŒ–æ–‡ä»¶å‘é‡...")
        self.timer.start_stage("å‘é‡åŒ–")
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰å‘é‡æ–‡ä»¶
        if self.vector_store.load():
            self.timer.stop_stage("å‘é‡åŒ–")
            print("âœ… ä½¿ç”¨å·²å„²å­˜çš„å‘é‡ï¼ˆå¿«é€Ÿå•Ÿå‹•ï¼‰")
            return
        
        # ç¬¬ä¸€æ¬¡å•Ÿå‹•ï¼Œéœ€è¦å‘é‡åŒ–
        print("âš ï¸  é¦–æ¬¡å•Ÿå‹•ï¼Œéœ€è¦èª¿ç”¨ OpenAI API ç”Ÿæˆå‘é‡")
        print("â³ é è¨ˆéœ€è¦ 10-15 ç§’ï¼Œè«‹ç¨å€™...")
        
        # è®€å–ä¸¦å‘é‡åŒ–æ–‡ä»¶
        if not os.path.exists(docs_dir):
            print(f"âš ï¸  æ–‡ä»¶ç›®éŒ„ä¸å­˜åœ¨: {docs_dir}")
            self.timer.stop_stage("å‘é‡åŒ–")
            return
        
        documents = []
        for filename in os.listdir(docs_dir):
            filepath = os.path.join(docs_dir, filename)
            if os.path.isfile(filepath) and filename.endswith('.txt'):
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    documents.append({
                        "id": filename,
                        "content": content,
                        "metadata": {"filename": filename}
                    })
                    print(f"  ğŸ“„ è¼‰å…¥: {filename} ({len(content)} å­—)")
        
        if documents:
            await self.vector_store.batch_add_documents(documents)
            self.vector_store.save()
            self.vector_store.export_to_json()
        
        self.timer.stop_stage("å‘é‡åŒ–")
    
    async def main_thread_rag(self, query: str) -> Dict:
        """
        ä¸»ç·šï¼ˆThread Aï¼‰ï¼šRAG æª¢ç´¢ï¼ˆä¸ç”Ÿæˆè‰ç¨¿ï¼‰
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            RAG æª¢ç´¢çµæœ
        """
        self.timer.start_stage("RAGæª¢ç´¢", thread='A')
        
        # RAG æª¢ç´¢
        retrieved_docs = await self.rag_retriever.retrieve(query, top_k=3)
        context = self.rag_retriever.format_context(retrieved_docs)
        matched_doc_ids = self.rag_retriever.get_matched_doc_ids(retrieved_docs)
        
        # æå–çŸ¥è­˜é»
        knowledge_points = []
        for doc_id in matched_doc_ids:
            if doc_id in Config.KNOWLEDGE_POINTS:
                knowledge_points.append(Config.KNOWLEDGE_POINTS[doc_id])
        
        self.timer.stop_stage("RAGæª¢ç´¢", thread='A')
        
        return {
            "context": context,
            "matched_docs": matched_doc_ids,
            "knowledge_points": knowledge_points,
            "retrieved_docs": retrieved_docs
        }
    
    async def parallel_dimension_classification(self, query: str, matched_docs: List[str]) -> Dict:
        """
        ä¸¦è¡ŒåŸ·è¡Œå››å€‹å‘åº¦åˆ¤å®šï¼ˆThread B, C, D, Eï¼‰
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            matched_docs: RAG åŒ¹é…åˆ°çš„æ–‡æª” ID
            
        Returns:
            æƒ…å¢ƒåˆ¤å®šçµæœ
        """
        # ç²å–æ­·å²å°è©±ï¼ˆåªæœ‰ D4 éœ€è¦ï¼‰
        history = self.history_manager.get_recent_history(5)
        history_list = [h.to_dict() for h in history]
        
        # ä¸¦è¡ŒåŸ·è¡Œå››å€‹å‘åº¦åˆ¤å®šï¼Œå‚³å…¥ RAG çµæœ
        result = await self.scenario_classifier.classify(query, history_list, matched_docs)
        
        return result
    
    async def final_round_generate(
        self, 
        rag_result: Dict, 
        scenario_result: Dict, 
        query: str
    ) -> str:
        """
        æœ€çµ‚å›åˆï¼šç°¡å–®å‘Šè¨´ AI ç•¶å‰æƒ…å¢ƒï¼Œçµåˆ RAG + æœ¬é«”è«–ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            rag_result: ä¸»ç·šçš„ RAG çµæœ
            scenario_result: åˆ†æ”¯çš„æƒ…å¢ƒåˆ¤å®šçµæœ
            query: ç”¨æˆ¶å•é¡Œ
            
        Returns:
            æœ€çµ‚ç­”æ¡ˆ
        """
        print("\nã€æœ€çµ‚å›åˆã€‘æ•´åˆ RAG + æœ¬é«”è«–ç”Ÿæˆç­”æ¡ˆ...")
        
        # æå–çµæœ
        context = rag_result['context']
        knowledge_points = rag_result['knowledge_points']
        
        scenario_number = scenario_result['scenario_number']
        dimensions = scenario_result['dimensions']
        
        # æ§‹å»ºæƒ…å¢ƒèªªæ˜æ–‡å­—ï¼ˆç°¡å–®æ˜ç­ï¼‰
        scenario_text = f"ç¾åœ¨ç‚ºç¬¬ {scenario_number} ç¨®æƒ…å¢ƒï¼Œä»£è¡¨ D1={dimensions['D1']}, D2={dimensions['D2']}, D3={dimensions['D3']}, D4={dimensions['D4']}"
        
        # è¼‰å…¥æœ¬é«”è«–
        ontology_content = self.ontology_manager.get_ontology_content()
        
        # æ§‹å»ºæœ€çµ‚æç¤ºè©ï¼ˆç°¡åŒ–ç‰ˆï¼Œä¸ä½¿ç”¨è¤‡é›œæ¨¡æ¿ï¼‰
        final_prompt = f"""
è«‹å›ç­”ä»¥ä¸‹å•é¡Œã€‚

ã€ç•¶å‰æƒ…å¢ƒã€‘
{scenario_text}

ã€RAG æª¢ç´¢åˆ°çš„æ•™æç‰‡æ®µã€‘
{context}

ã€çŸ¥è­˜æœ¬é«”è«–ã€‘
{ontology_content}

ã€åŒ¹é…çš„çŸ¥è­˜é»ã€‘
{', '.join(knowledge_points) if knowledge_points else 'ç„¡'}

ã€ç”¨æˆ¶å•é¡Œã€‘
{query}

è«‹æ ¹æ“šä¸Šè¿°è³‡è¨Šç”Ÿæˆå›ç­”ã€‚åœ¨å›ç­”é–‹é ­ç°¡è¦èªªæ˜ï¼šã€Œ{scenario_text}ã€

**é‡è¦ï¼šå›ç­”é™åˆ¶åœ¨ 100 å­—ä»¥å…§ã€‚**
"""
        
        print(f"ã€æœ€çµ‚å›åˆã€‘æƒ…å¢ƒï¼š{scenario_text}")
        
        # ä½¿ç”¨ Responses API ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆï¼ˆæµå¼ï¼‰
        response = self.client.chat.completions.create(
            model=Config.LLM_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çŸ¥è­˜åŠ©æ‰‹ã€‚å›ç­”é™åˆ¶åœ¨ 100 å­—ä»¥å…§ã€‚"},
                {"role": "user", "content": final_prompt}
            ],
            temperature=Config.LLM_TEMPERATURE,
            max_tokens=200,  # 100 å­—ç´„ 200 tokens
            stream=True
        )
        
        print("\nğŸ’¬ ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆï¼ˆæµå¼è¼¸å‡ºï¼‰...")
        print("-" * 60)
        
        final_answer = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                final_answer += content
        
        print("\n" + "-" * 60)
        
        return final_answer
    
    async def process_query(self, query: str) -> Dict:
        """
        è™•ç†æŸ¥è©¢ï¼ˆäº”å€‹ä¸¦è¡Œåˆ†æ”¯ + æœ€çµ‚ç”Ÿæˆï¼‰
        
        ç¬¬ä¸€å›åˆï¼šä¸¦è¡ŒåŸ·è¡Œ RAG æª¢ç´¢ + å››å€‹å‘åº¦åˆ¤å®šï¼ˆ5å€‹åˆ†æ”¯ï¼‰
        ç¬¬äºŒå›åˆï¼šæ•´åˆçµæœï¼Œç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            è™•ç†çµæœ
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“¥ æ”¶åˆ°æŸ¥è©¢: {query}")
        print(f"{'='*70}")
        
        # ç¬¬ä¸€å›åˆï¼šçœŸæ­£çš„ä¸¦è¡ŒåŸ·è¡Œï¼ˆRAG + å››å€‹å‘åº¦åˆ¤å®šï¼‰
        self.timer.start_stage("ä¸¦è¡Œè™•ç†ï¼ˆ5å€‹åˆ†æ”¯ï¼‰")
        
        # âœ… çœŸæ­£çš„ä¸¦è¡Œï¼šåŒæ™‚åŸ·è¡Œ RAG å’Œå››å€‹å‘åº¦åˆ¤å®š
        # D4 API ä¸å†ä¾è³´ RAG çµæœï¼Œæ‰€ä»¥å¯ä»¥å®Œå…¨ä¸¦è¡Œ
        rag_task = self.main_thread_rag(query)
        scenario_task = self.parallel_dimension_classification(query, None)  # ä¸å‚³å…¥ matched_docs
        
        # ç­‰å¾…å…©è€…éƒ½å®Œæˆ
        rag_result, scenario_result = await asyncio.gather(rag_task, scenario_task)
        
        self.timer.stop_stage("ä¸¦è¡Œè™•ç†ï¼ˆ5å€‹åˆ†æ”¯ï¼‰")
        print(f"\nâœ… çœŸæ­£çš„ä¸¦è¡Œå®Œæˆï¼šRAG + å››å€‹å‘åº¦åˆ¤å®šåŒæ™‚åŸ·è¡Œ\n")
        
        # ç¬¬äºŒå›åˆï¼šç”Ÿæˆç­”æ¡ˆ
        self.timer.start_stage("æœ€çµ‚å›åˆç”Ÿæˆ")
        
        final_answer = await self.final_round_generate(rag_result, scenario_result, query)
        
        self.timer.stop_stage("æœ€çµ‚å›åˆç”Ÿæˆ")
        self.timer.stop_stage("ç¸½æµç¨‹")
        
        # æ‰“å°è©³ç´°è¨ˆæ™‚å ±å‘Š
        self.timer.print_report()
        
        # è¨˜éŒ„åˆ°æ­·å²
        dimensions_dict = {
            "D1": "ä¸€å€‹",  # TODO: å¾ RAG çµæœè¨ˆç®—
            "D2": scenario_result['dimensions']['D2'],
            "D3": scenario_result['dimensions']['D3'],
            "D4": scenario_result['dimensions']['D4']
        }
        
        self.history_manager.add_query(
            query,
            rag_result['matched_docs'],
            dimensions_dict,
            scenario_result.get('knowledge_binary', '0000')  # å‚³å…¥äºŒé€²åˆ¶ç·¨ç¢¼
        )
        
        # ============ è¿”å›çµæœ ============
        result = {
            "query": query,
            "final_answer": final_answer,
            "scenario_number": scenario_result['scenario_number'],
            "scenario_description": scenario_result['description'],
            "dimensions": scenario_result['dimensions'],
            "matched_docs": rag_result['matched_docs'],
            "knowledge_points": rag_result['knowledge_points'],
            "time_report": self.timer.get_report().to_dict()
        }
        
        return result
    
    def print_summary(self, result: Dict):
        """æ‰“å°çµæœæ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸ“Š Responses API é›™å›åˆè™•ç†çµæœæ‘˜è¦")
        print("="*70)
        print(f"æŸ¥è©¢ï¼š{result['query']}")
        print(f"\nğŸ¯ æƒ…å¢ƒåˆ¤å®šï¼šç¬¬ {result['scenario_number']} ç¨®æƒ…å¢ƒ")
        print(f"   æè¿°ï¼š{result['scenario_description']}")
        print(f"\nğŸ“ å››å‘åº¦åˆ†æï¼š")
        for dim, value in result['dimensions'].items():
            print(f"   {dim}: {value}")
        print(f"\nğŸ“š åŒ¹é…çŸ¥è­˜é»ï¼š{', '.join(result['knowledge_points']) if result['knowledge_points'] else 'ç„¡'}")
        print(f"\nâ±ï¸  åŸ·è¡Œæ™‚é–“åˆ†æï¼š")
        time_report = result['time_report']
        
        # ä¸»æµç¨‹æ™‚é–“
        if 'stages' in time_report:
            print("  â”Œâ”€ ã€ä¸»æµç¨‹ - ç¸½é«”æ™‚é–“ã€‘")
            for stage, duration in time_report['stages'].items():
                print(f"  â”‚   {stage:30s}: {duration:6.3f}s")
        
        # Thread A æ™‚é–“ï¼ˆRAG æª¢ç´¢ï¼‰
        if 'thread_a' in time_report:
            print(f"  â”œâ”€ ã€{time_report['thread_a']['thread_name']}ã€‘")
            for stage, duration in time_report['thread_a']['stages'].items():
                print(f"  â”‚   {stage:30s}: {duration:6.3f}s")
            print(f"  â”‚   {'â”€' * 40}")
            print(f"  â”‚   {'ä¸»ç·šå°è¨ˆ':30s}: {time_report['thread_a']['total_time']:6.3f}s")
        
        # Thread B æ™‚é–“ï¼ˆResponses API æƒ…å¢ƒåˆ¤å®šï¼‰
        if 'thread_b' in time_report:
            print(f"  â””â”€ ã€{time_report['thread_b']['thread_name']}ã€‘")
            for stage, duration in time_report['thread_b']['stages'].items():
                print(f"      {stage:30s}: {duration:6.3f}s")
            print(f"      {'â”€' * 40}")
            print(f"      {'æ”¯ç·šå°è¨ˆ':30s}: {time_report['thread_b']['total_time']:6.3f}s")
        
        print(f"\n  ğŸ¯ ç¸½è¨ˆæ™‚é–“: {time_report['total_time']:.3f}s")
        print("="*70)


async def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "="*70)
    print("ğŸš€ Responses API é›™å›åˆ RAG ç³»çµ±")
    print("="*70)
    
    # åˆå§‹åŒ–ç³»çµ±
    system = ResponsesRAGSystem()
    
    # åˆå§‹åŒ–æ–‡ä»¶
    await system.initialize_documents()
    
    # æ¸¬è©¦æŸ¥è©¢
    test_queries = [
        "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
        "æ©Ÿå™¨å­¸ç¿’å’Œæ·±åº¦å­¸ç¿’æœ‰ä»€éº¼å€åˆ¥ï¼Ÿ"
    ]
    
    for query in test_queries:
        result = await system.process_query(query)
        system.print_summary(result)
        print("\n")


if __name__ == "__main__":
    asyncio.run(main())
