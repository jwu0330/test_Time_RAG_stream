#!/bin/bash
# é©—è­‰ Responses API function call åŠŸèƒ½

echo "ðŸ” é©—è­‰ Responses API Function Call åŠŸèƒ½"
echo "=========================================="
echo ""

# å‰µå»ºè‡¨æ™‚æ¸¬è©¦è…³æœ¬
cat > /tmp/test_function_call.py << 'EOF'
import os
from openai import OpenAI

client = OpenAI()

# æ¸¬è©¦ function call
tools = [{
    "type": "function",
    "function": {
        "name": "classify_scenario",
        "description": "åˆ¤å®šæƒ…å¢ƒç·¨è™Ÿ",
        "parameters": {
            "type": "object",
            "properties": {
                "scenario_id": {
                    "type": "integer",
                    "description": "æƒ…å¢ƒç·¨è™Ÿï¼ˆ1-24ï¼‰",
                    "minimum": 1,
                    "maximum": 24
                }
            },
            "required": ["scenario_id"],
            "additionalProperties": False
        },
        "strict": True
    }
}]

try:
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯æƒ…å¢ƒåˆ†æžåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "è«‹åˆ¤å®šï¼šä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿé€™æ˜¯ç¬¬å¹¾ç¨®æƒ…å¢ƒï¼Ÿ"}
        ],
        tools=tools,
        tool_choice={"type": "function", "function": {"name": "classify_scenario"}},
        temperature=0,
        max_tokens=50
    )
    
    message = response.choices[0].message
    if message.tool_calls:
        import json
        tool_call = message.tool_calls[0]
        args = json.loads(tool_call.function.arguments)
        print(f"âœ… Function Call æˆåŠŸï¼")
        print(f"   è¿”å›žæƒ…å¢ƒç·¨è™Ÿ: {args.get('scenario_id')}")
    else:
        print("âš ï¸  æœªæ”¶åˆ° tool call")
        
except Exception as e:
    print(f"âŒ éŒ¯èª¤: {e}")
    import traceback
    traceback.print_exc()
EOF

# åŸ·è¡Œæ¸¬è©¦
python3 /tmp/test_function_call.py

# æ¸…ç†
rm /tmp/test_function_call.py

echo ""
echo "âœ… é©—è­‰å®Œæˆ"
