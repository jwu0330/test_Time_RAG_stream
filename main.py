"""
ä¸»ç¨‹åº - RAG æµå¼ä¸­æ–·èˆ‡çºŒå¯«ç³»çµ±
æ”¯æ´å‘é‡å„²å­˜ã€æƒ…å¢ƒæ³¨å…¥ã€æ™‚é–“åˆ†æ
"""
import asyncio
import json
import os
from datetime import datetime
from typing import Dict, List, Optional
from openai import OpenAI

from vector_store import VectorStore
from rag_module import RAGRetriever, RAGCache
from scenario_module import ScenarioClassifier, ScenarioInjector
from timer_utils import Timer


class RAGStreamSystem:
    """RAG æµå¼ç³»çµ±ä¸»é¡"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–ç³»çµ±
        
        Args:
            api_key: OpenAI API Key (å¦‚æœä¸æä¾›ï¼Œå°‡å¾ç’°å¢ƒè®Šé‡è®€å–)
        """
        self.api_key = api_key
        self.client = OpenAI(api_key=api_key) if api_key else OpenAI()
        
        # åˆå§‹åŒ–å„æ¨¡çµ„
        self.vector_store = VectorStore(api_key=api_key)
        self.rag_retriever = RAGRetriever(self.vector_store)
        self.rag_cache = RAGCache()
        self.scenario_classifier = ScenarioClassifier(api_key=api_key)
        self.scenario_injector = ScenarioInjector(self.scenario_classifier)
        
        # ç³»çµ±ç‹€æ…‹
        self.draft_response = ""
        self.timer = Timer()
        
        print("ğŸš€ RAG æµå¼ç³»çµ±å·²åˆå§‹åŒ–")
    
    async def initialize_documents(self, docs_dir: str = "docs"):
        """
        åˆå§‹åŒ–æ–‡ä»¶å‘é‡åŒ–
        
        Args:
            docs_dir: æ–‡ä»¶ç›®éŒ„
        """
        print(f"\nğŸ“š é–‹å§‹å‘é‡åŒ–æ–‡ä»¶...")
        self.timer.start_stage("å‘é‡åŒ–")
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰å‘é‡æ–‡ä»¶
        if self.vector_store.load():
            self.timer.stop_stage("å‘é‡åŒ–")
            print("âœ… ä½¿ç”¨å·²å„²å­˜çš„å‘é‡")
            return
        
        # è®€å–ä¸¦å‘é‡åŒ–æ–‡ä»¶
        if not os.path.exists(docs_dir):
            print(f"âš ï¸  æ–‡ä»¶ç›®éŒ„ä¸å­˜åœ¨: {docs_dir}")
            self.timer.stop_stage("å‘é‡åŒ–")
            return
        
        documents = []
        for filename in os.listdir(docs_dir):
            filepath = os.path.join(docs_dir, filename)
            if os.path.isfile(filepath):
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    documents.append({
                        "id": filename,
                        "content": content,
                        "metadata": {"filename": filename}
                    })
        
        if documents:
            await self.vector_store.batch_add_documents(documents)
            self.vector_store.save()
            self.vector_store.export_to_json()
        
        self.timer.stop_stage("å‘é‡åŒ–")
    
    async def load_scenarios(self, scenarios_dir: str = "scenarios"):
        """
        è¼‰å…¥æƒ…å¢ƒæ–‡ä»¶
        
        Args:
            scenarios_dir: æƒ…å¢ƒç›®éŒ„
        """
        print(f"\nğŸ­ è¼‰å…¥æƒ…å¢ƒ...")
        self.scenario_classifier.load_scenarios_from_dir(scenarios_dir)
    
    async def generate_draft(self, query: str, context: str) -> str:
        """
        ç”Ÿæˆé€šç”¨è‰ç¨¿ï¼ˆä¸è¼¸å‡ºï¼Œåƒ…å…§éƒ¨ä¿å­˜ï¼‰
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            context: RAG æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
            
        Returns:
            è‰ç¨¿å…§å®¹
        """
        print("\nğŸ“ ç”Ÿæˆé€šç”¨è‰ç¨¿...")
        self.timer.start_stage("LLMè‰ç¨¿ç”Ÿæˆ")
        
        prompt = f"""
åŸºæ–¼ä»¥ä¸‹æª¢ç´¢åˆ°çš„ç›¸é—œæ–‡ä»¶ï¼Œå›ç­”ç”¨æˆ¶çš„å•é¡Œã€‚
é€™æ˜¯ä¸€å€‹åˆæ­¥è‰ç¨¿ï¼Œç¨å¾Œæœƒæ ¹æ“šå…·é«”æƒ…å¢ƒé€²è¡Œèª¿æ•´ã€‚

ç›¸é—œæ–‡ä»¶ï¼š
{context}

ç”¨æˆ¶å•é¡Œï¼š
{query}

è«‹æä¾›ä¸€å€‹çµæ§‹åŒ–çš„åˆæ­¥å›ç­”ã€‚
"""
        
        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        draft = response.choices[0].message.content
        self.draft_response = draft
        
        self.timer.stop_stage("LLMè‰ç¨¿ç”Ÿæˆ")
        print("âœ… è‰ç¨¿å·²ç”Ÿæˆï¼ˆæš«å­˜ä¸­ï¼‰")
        
        return draft
    
    async def resume_with_scenario(
        self, 
        query: str,
        scenario_ids: List[str]
    ) -> str:
        """
        æ ¹æ“šæƒ…å¢ƒçºŒå¯«æœ€çµ‚ç­”æ¡ˆ
        
        Args:
            query: åŸå§‹æŸ¥è©¢
            scenario_ids: æƒ…å¢ƒ ID åˆ—è¡¨
            
        Returns:
            æœ€çµ‚ç­”æ¡ˆ
        """
        print(f"\nğŸ¯ æ³¨å…¥æƒ…å¢ƒä¸¦çºŒå¯«: {', '.join(scenario_ids)}")
        self.timer.start_stage("æƒ…å¢ƒæ³¨å…¥èˆ‡çºŒå¯«")
        
        # ç²å–æƒ…å¢ƒå…§å®¹
        scenario_context = self.scenario_classifier.format_scenario_context(scenario_ids)
        
        # å‰µå»ºæ³¨å…¥æç¤º
        injection_prompt = self.scenario_injector.create_injection_prompt(
            draft_response=self.draft_response,
            scenario_context=scenario_context,
            original_query=query
        )
        
        # æµå¼ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ
        print("\nğŸ’¬ æœ€çµ‚å›ç­”ï¼š")
        print("-" * 50)
        
        stream = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": injection_prompt}
            ],
            temperature=0.7,
            stream=True
        )
        
        final_answer = ""
        for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                final_answer += content
        
        print("\n" + "-" * 50)
        
        self.timer.stop_stage("æƒ…å¢ƒæ³¨å…¥èˆ‡çºŒå¯«")
        
        return final_answer
    
    async def process_query(
        self, 
        query: str,
        scenario_ids: Optional[List[str]] = None,
        auto_classify: bool = True
    ) -> Dict:
        """
        è™•ç†å®Œæ•´æŸ¥è©¢æµç¨‹
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            scenario_ids: æŒ‡å®šçš„æƒ…å¢ƒ IDï¼ˆå¦‚æœç‚º None å‰‡è‡ªå‹•åˆ†é¡ï¼‰
            auto_classify: æ˜¯å¦è‡ªå‹•é€²è¡Œæƒ…å¢ƒåˆ†é¡
            
        Returns:
            å®Œæ•´çµæœå­—å…¸
        """
        print("\n" + "="*60)
        print(f"ğŸ” è™•ç†æŸ¥è©¢: {query}")
        print("="*60)
        
        # é‡ç½®è¨ˆæ™‚å™¨
        self.timer = Timer()
        
        # Step 1: RAG æª¢ç´¢
        print("\nğŸ“Š Step 1: RAG æª¢ç´¢")
        self.timer.start_stage("RAGæª¢ç´¢")
        
        retrieved_docs = await self.rag_retriever.retrieve(query, top_k=3)
        context = self.rag_retriever.format_context(retrieved_docs)
        matched_doc_ids = self.rag_retriever.get_matched_doc_ids(retrieved_docs)
        
        self.timer.stop_stage("RAGæª¢ç´¢")
        print(f"âœ… æ‰¾åˆ° {len(retrieved_docs)} å€‹ç›¸é—œæ–‡ä»¶")
        
        # Step 2: æƒ…å¢ƒåˆ†é¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if auto_classify and not scenario_ids:
            print("\nğŸ¯ Step 2: æƒ…å¢ƒåˆ†é¡")
            self.timer.start_stage("æƒ…å¢ƒåˆ†é¡")
            
            classification = await self.scenario_classifier.classify_scenario(
                query=query,
                context=context
            )
            scenario_ids = self.scenario_classifier.get_scenario_by_dimensions(classification)
            
            self.timer.stop_stage("æƒ…å¢ƒåˆ†é¡")
            print(f"âœ… æ¨è–¦æƒ…å¢ƒ: {', '.join(scenario_ids) if scenario_ids else 'ç„¡'}")
        
        # Step 3: ç”Ÿæˆè‰ç¨¿
        print("\nğŸ“ Step 3: ç”Ÿæˆé€šç”¨è‰ç¨¿")
        draft = await self.generate_draft(query, context)
        
        # Step 4: æ¨¡æ“¬æš«åœï¼ˆstream interruptionï¼‰
        print("\nâ¸ï¸  Step 4: æµå¼æš«åœï¼ˆç­‰å¾…æƒ…å¢ƒæ³¨å…¥ï¼‰")
        await asyncio.sleep(0.5)  # æ¨¡æ“¬æš«åœ
        
        # Step 5: æƒ…å¢ƒæ³¨å…¥èˆ‡çºŒå¯«
        print("\nâ–¶ï¸  Step 5: æƒ…å¢ƒæ³¨å…¥èˆ‡çºŒå¯«")
        if not scenario_ids:
            scenario_ids = []
        
        final_answer = await self.resume_with_scenario(query, scenario_ids)
        
        # Step 6: èƒŒæ™¯ä»»å‹™æ¨¡æ“¬
        print("\nğŸ”„ Step 6: åŸ·è¡ŒèƒŒæ™¯ä»»å‹™")
        await self.run_background_tasks()
        
        # ç”Ÿæˆå ±å‘Š
        report = self.timer.get_report()
        
        result = {
            "query": query,
            "final_answer": final_answer,
            "scenario_used": "+".join(scenario_ids) if scenario_ids else "ç„¡",
            "matched_docs": matched_doc_ids,
            "time_report": report.to_dict()
        }
        
        return result
    
    async def run_background_tasks(self):
        """åŸ·è¡ŒèƒŒæ™¯ä»»å‹™ï¼ˆæ¨¡æ“¬ï¼‰"""
        self.timer.start_stage("èƒŒæ™¯ä»»å‹™")
        
        tasks = [
            self.update_color_tags(),
            self.save_cache_annotations(),
            self.log_activity()
        ]
        
        await asyncio.gather(*tasks)
        
        self.timer.stop_stage("èƒŒæ™¯ä»»å‹™")
        print("âœ… èƒŒæ™¯ä»»å‹™å®Œæˆ")
    
    async def update_color_tags(self):
        """æ›´æ–°é¡è‰²æ¨™ç±¤ï¼ˆæ¨¡æ“¬ï¼‰"""
        await asyncio.sleep(0.2)
        print("  ğŸ¨ é¡è‰²æ¨™ç±¤å·²æ›´æ–°")
    
    async def save_cache_annotations(self):
        """å„²å­˜å¿«å–æ¨™è¨»ï¼ˆæ¨¡æ“¬ï¼‰"""
        await asyncio.sleep(0.3)
        print("  ğŸ’¾ å¿«å–æ¨™è¨»å·²å„²å­˜")
    
    async def log_activity(self):
        """è¨˜éŒ„æ´»å‹•æ—¥èªŒï¼ˆæ¨¡æ“¬ï¼‰"""
        await asyncio.sleep(0.1)
        print("  ğŸ“‹ æ´»å‹•æ—¥èªŒå·²è¨˜éŒ„")
    
    def save_result(self, result: Dict, output_dir: str = "results"):
        """
        å„²å­˜çµæœåˆ°æ–‡ä»¶
        
        Args:
            result: çµæœå­—å…¸
            output_dir: è¼¸å‡ºç›®éŒ„
        """
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"result_{timestamp}.json"
        filepath = os.path.join(output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ çµæœå·²å„²å­˜è‡³: {filepath}")
    
    def print_summary(self, result: Dict):
        """æ‰“å°çµæœæ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š åŸ·è¡Œæ‘˜è¦")
        print("="*60)
        print(f"æŸ¥è©¢: {result['query']}")
        print(f"ä½¿ç”¨æƒ…å¢ƒ: {result['scenario_used']}")
        print(f"åŒ¹é…æ–‡ä»¶: {', '.join(result['matched_docs'])}")
        print(f"\nâ±ï¸  æ™‚é–“åˆ†æ:")
        for stage, duration in result['time_report']['stages'].items():
            print(f"  {stage:20s}: {duration:6.3f}s")
        print(f"  {'ç¸½è¨ˆ':20s}: {result['time_report']['total_time']:6.3f}s")
        print("="*60)


async def main():
    """ä¸»å‡½æ•¸ - ç¤ºä¾‹ä½¿ç”¨"""
    
    # åˆå§‹åŒ–ç³»çµ±
    system = RAGStreamSystem()
    
    # åˆå§‹åŒ–æ–‡ä»¶å’Œæƒ…å¢ƒ
    await system.initialize_documents()
    await system.load_scenarios()
    
    # æ¸¬è©¦æŸ¥è©¢
    test_queries = [
        "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
        "å¦‚ä½•å„ªåŒ–æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Ÿ",
        "è§£é‡‹ä¸€ä¸‹è‡ªç„¶èªè¨€è™•ç†çš„åŸºæœ¬æ¦‚å¿µ"
    ]
    
    print("\n" + "="*60)
    print("ğŸ§ª é–‹å§‹æ¸¬è©¦å›åˆ")
    print("="*60)
    
    results = []
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n\n{'='*60}")
        print(f"æ¸¬è©¦ {i}/{len(test_queries)}")
        print(f"{'='*60}")
        
        result = await system.process_query(query)
        results.append(result)
        
        system.print_summary(result)
        system.save_result(result)
        
        # é–“éš”
        if i < len(test_queries):
            await asyncio.sleep(1)
    
    # å¹³å‡æ™‚é–“åˆ†æ
    print("\n" + "="*60)
    print("ğŸ“ˆ å¹³å‡æ•ˆèƒ½åˆ†æ")
    print("="*60)
    
    avg_times = {}
    for result in results:
        for stage, duration in result['time_report']['stages'].items():
            if stage not in avg_times:
                avg_times[stage] = []
            avg_times[stage].append(duration)
    
    for stage, times in avg_times.items():
        avg = sum(times) / len(times)
        print(f"  {stage:20s}: {avg:6.3f}s (å¹³å‡)")
    
    total_avg = sum(r['time_report']['total_time'] for r in results) / len(results)
    print(f"  {'ç¸½è¨ˆ':20s}: {total_avg:6.3f}s (å¹³å‡)")
    print("="*60)
    
    print("\nâœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())
