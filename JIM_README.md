# ğŸš€ RAG æµå¼ä¸­æ–·èˆ‡çºŒå¯«ç³»çµ± - Jim å®Œæ•´æ–‡æª”

## ğŸ“‹ ç›®éŒ„
1. [ç³»çµ±æ¦‚è¿°](#ç³»çµ±æ¦‚è¿°)
2. [å°ˆæ¡ˆçµæ§‹](#å°ˆæ¡ˆçµæ§‹)
3. [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
4. [æŠ€è¡“æ¶æ§‹](#æŠ€è¡“æ¶æ§‹)
5. [å®‰è£èˆ‡é…ç½®](#å®‰è£èˆ‡é…ç½®)
6. [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)
7. [æ¨¡çµ„è©³è§£](#æ¨¡çµ„è©³è§£)
8. [å·¥ä½œæµç¨‹](#å·¥ä½œæµç¨‹)
9. [æ¸¬è©¦èˆ‡é©—è­‰](#æ¸¬è©¦èˆ‡é©—è­‰)
10. [æ•ˆèƒ½åˆ†æ](#æ•ˆèƒ½åˆ†æ)
11. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)
12. [é€²éšåŠŸèƒ½](#é€²éšåŠŸèƒ½)

---

## ğŸ¯ ç³»çµ±æ¦‚è¿°

é€™æ˜¯ä¸€å€‹**æœ€å°å¯è¡Œçš„ RAG (Retrieval-Augmented Generation) ç³»çµ±**ï¼Œå…·å‚™ä»¥ä¸‹æ ¸å¿ƒç‰¹æ€§ï¼š

### ä¸»è¦ç‰¹é»
- âœ… **å‘é‡å„²å­˜èˆ‡å¿«é€Ÿè¼‰å…¥**ï¼šæ•™æå‘é‡åŒ–å¾Œå¯æŒä¹…åŒ–å„²å­˜ï¼Œé¿å…é‡è¤‡è¨ˆç®—
- âœ… **æµå¼ä¸­æ–·èˆ‡çºŒå¯«**ï¼šæ”¯æ´ Stream Interruption & Resume æ©Ÿåˆ¶
- âœ… **æƒ…å¢ƒæ³¨å…¥**ï¼šå››å‘åº¦æƒ…å¢ƒåˆ†é¡ (D1-D4) èˆ‡å‹•æ…‹æ³¨å…¥
- âœ… **ç²¾æº–æ™‚é–“åˆ†æ**ï¼šä½¿ç”¨ `time.perf_counter()` è¨˜éŒ„å„éšæ®µè€—æ™‚
- âœ… **èƒŒæ™¯ä»»å‹™æ¨¡æ“¬**ï¼šç•°æ­¥åŸ·è¡Œé¡è‰²æ¨™ç±¤ã€å¿«å–æ¨™è¨»ç­‰ä»»å‹™
- âœ… **å¯é‡è¤‡æ¸¬è©¦**ï¼šæ”¯æ´å¤šè¼ªæ¸¬è©¦èˆ‡æ•ˆèƒ½æ¯”è¼ƒ

### è¨­è¨ˆåŸå‰‡
- ğŸ¯ **æœ€å°æ¸¬è©¦ç¯„åœ**ï¼šå°ˆæ³¨æ ¸å¿ƒåŠŸèƒ½ï¼Œé¿å…éåº¦è¨­è¨ˆ
- â±ï¸ **ç²¾æº–æ™‚é–“åˆ†æ**ï¼šæ¯å€‹éšæ®µéƒ½æœ‰ç¨ç«‹è¨ˆæ™‚
- ğŸ”„ **å¯é‡è¤‡åŸ·è¡Œ**ï¼šæ”¯æ´å¿«å–èˆ‡å¢é‡æ›´æ–°
- ğŸ› **å¯åµéŒ¯ä¿®æ­£**ï¼šæ¸…æ™°çš„æ—¥èªŒèˆ‡éŒ¯èª¤è™•ç†

---

## ğŸ“‚ å°ˆæ¡ˆçµæ§‹

```
rag_stream_resume/
â”œâ”€â”€ main.py                 # ä¸»ç¨‹åº - ç³»çµ±å…¥å£èˆ‡æµç¨‹ç·¨æ’
â”œâ”€â”€ vector_store.py         # å‘é‡å„²å­˜æ¨¡çµ„ - embeddings ç”Ÿæˆèˆ‡ç®¡ç†
â”œâ”€â”€ rag_module.py           # RAG æª¢ç´¢æ¨¡çµ„ - ç›¸ä¼¼åº¦è¨ˆç®—èˆ‡æ–‡ä»¶æª¢ç´¢
â”œâ”€â”€ scenario_module.py      # æƒ…å¢ƒåˆ¤å®šæ¨¡çµ„ - å››å‘åº¦åˆ†é¡èˆ‡æ³¨å…¥
â”œâ”€â”€ timer_utils.py          # æ™‚é–“åˆ†ææ¨¡çµ„ - ç²¾æº–è¨ˆæ™‚å·¥å…·
â”œâ”€â”€ requirements.txt        # Python ä¾è³´å¥—ä»¶
â”œâ”€â”€ JIM_README.md          # æœ¬æ–‡æª”
â”‚
â”œâ”€â”€ docs/                   # ğŸ“š æ•™æä¸Šå‚³è³‡æ–™å¤¾
â”‚   â”œâ”€â”€ doc1.txt
â”‚   â”œâ”€â”€ doc2.txt
â”‚   â””â”€â”€ doc3.txt
â”‚
â”œâ”€â”€ scenarios/              # ğŸ­ æƒ…å¢ƒ JSON/TXT æª”æ¡ˆ
â”‚   â”œâ”€â”€ scenario1.json
â”‚   â”œâ”€â”€ scenario2.json
â”‚   â””â”€â”€ scenario3.txt
â”‚
â”œâ”€â”€ results/                # ğŸ“Š æ¸¬è©¦çµæœè¼¸å‡º
â”‚   â””â”€â”€ result_20251008_122638.json
â”‚
â”œâ”€â”€ vectors.pkl             # ğŸ’¾ å‘é‡å„²å­˜æ–‡ä»¶ (pickle æ ¼å¼)
â””â”€â”€ vectors.json            # ğŸ“„ å‘é‡å…ƒæ•¸æ“š (JSON æ ¼å¼)
```

---

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### 1ï¸âƒ£ å‘é‡åŒ–èˆ‡å„²å­˜ (Step 1-3)
- ä½¿ç”¨ OpenAI `text-embedding-3-small` æ¨¡å‹ç”Ÿæˆå‘é‡
- æ”¯æ´ pickle å’Œ JSON å…©ç¨®å„²å­˜æ ¼å¼
- è‡ªå‹•æª¢æ¸¬å·²å­˜åœ¨çš„å‘é‡æ–‡ä»¶ï¼Œé¿å…é‡è¤‡è¨ˆç®—
- å¿«é€Ÿè¼‰å…¥èˆ‡ç›¸ä¼¼åº¦æ¯”å°

### 2ï¸âƒ£ LLM é€šç”¨è‰æ¡ˆ (Step 4)
- åŸºæ–¼ RAG æª¢ç´¢çµæœç”Ÿæˆåˆæ­¥å›ç­”
- è‰ç¨¿æš«å­˜æ–¼è¨˜æ†¶é«”ï¼Œä¸ç›´æ¥è¼¸å‡º
- æ¨¡æ“¬ Stream Pause æ©Ÿåˆ¶

### 3ï¸âƒ£ æƒ…å¢ƒæ³¨å…¥èˆ‡çºŒå¯« (Step 5)
- å››å‘åº¦æƒ…å¢ƒåˆ†é¡ï¼š
  - **D1**: æ™‚é–“æ•æ„Ÿæ€§ (Time Sensitivity)
  - **D2**: æƒ…å¢ƒè¤‡é›œåº¦ (Context Complexity)
  - **D3**: å°ˆæ¥­é ˜åŸŸ (Domain Expertise)
  - **D4**: äº’å‹•æ¨¡å¼ (Interaction Mode)
- å‹•æ…‹æ³¨å…¥æƒ…å¢ƒå¾ŒçºŒå¯«æœ€çµ‚ç­”æ¡ˆ
- æ”¯æ´æµå¼è¼¸å‡º (Stream Mode)

### 4ï¸âƒ£ æ™‚é–“è¨˜éŒ„èˆ‡å ±å‘Š (Step 6)
- ä½¿ç”¨ `time.perf_counter()` ç²¾æº–è¨ˆæ™‚
- è¨˜éŒ„å„éšæ®µè€—æ™‚ï¼š
  - å‘é‡åŒ–
  - RAG æª¢ç´¢
  - æƒ…å¢ƒåˆ†é¡
  - LLM è‰ç¨¿ç”Ÿæˆ
  - æƒ…å¢ƒæ³¨å…¥èˆ‡çºŒå¯«
  - èƒŒæ™¯ä»»å‹™
- è¼¸å‡º JSON æ ¼å¼å ±å‘Š

### 5ï¸âƒ£ èƒŒæ™¯ä»»å‹™æ¨¡æ“¬ (Step 7)
- ç•°æ­¥åŸ·è¡Œå¤šå€‹èƒŒæ™¯ä»»å‹™ï¼š
  - é¡è‰²æ¨™ç±¤æ›´æ–°
  - å¿«å–æ¨™è¨»å„²å­˜
  - æ´»å‹•æ—¥èªŒè¨˜éŒ„
- ä½¿ç”¨ `asyncio.gather()` ä¸¦è¡ŒåŸ·è¡Œ

### 6ï¸âƒ£ æ¸¬è©¦å›åˆ (Step 8)
- æ”¯æ´å¤šæ¬¡æ¸¬è©¦è¼¸å…¥
- è¨ˆç®—å¹³å‡è€—æ™‚èˆ‡å·®ç•°
- ç”Ÿæˆæ•ˆèƒ½æ¯”è¼ƒåˆ†æ

---

## ğŸ—ï¸ æŠ€è¡“æ¶æ§‹

### æŠ€è¡“æ£§
| æ¨¡çµ„ | æŠ€è¡“ | èªªæ˜ |
|------|------|------|
| **å‘é‡ç”Ÿæˆ** | OpenAI Embeddings API | `text-embedding-3-small` æ¨¡å‹ |
| **å‘é‡å„²å­˜** | Pickle / JSON | æœ¬åœ°æŒä¹…åŒ–å„²å­˜ |
| **ç›¸ä¼¼åº¦è¨ˆç®—** | NumPy | é¤˜å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity) |
| **LLM èª¿ç”¨** | OpenAI Chat Completions | GPT-3.5-turbo / GPT-4 |
| **ç•°æ­¥è™•ç†** | asyncio | ä¸¦è¡ŒåŸ·è¡Œèˆ‡æµç¨‹ç·¨æ’ |
| **æ™‚é–“æ¸¬é‡** | time.perf_counter() | é«˜ç²¾åº¦è¨ˆæ™‚ |
| **æ•¸æ“šæ ¼å¼** | JSON | çµæœè¼¸å‡ºèˆ‡æƒ…å¢ƒå®šç¾© |

### ç³»çµ±æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAGStreamSystem                       â”‚
â”‚                      (ä¸»ç³»çµ±é¡)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VectorStore  â”‚   â”‚ RAGRetriever â”‚   â”‚  Scenario    â”‚
â”‚              â”‚   â”‚              â”‚   â”‚  Classifier  â”‚
â”‚ - å‘é‡ç”Ÿæˆ   â”‚   â”‚ - ç›¸ä¼¼åº¦è¨ˆç®— â”‚   â”‚ - å››å‘åº¦åˆ†é¡ â”‚
â”‚ - å„²å­˜/è¼‰å…¥  â”‚   â”‚ - Top-K æª¢ç´¢ â”‚   â”‚ - æƒ…å¢ƒæ³¨å…¥   â”‚
â”‚ - å¿«å–ç®¡ç†   â”‚   â”‚ - å¿«å–æ©Ÿåˆ¶   â”‚   â”‚ - çºŒå¯«æç¤º   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Timer     â”‚
                    â”‚              â”‚
                    â”‚ - éšæ®µè¨ˆæ™‚   â”‚
                    â”‚ - å ±å‘Šç”Ÿæˆ   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ å®‰è£èˆ‡é…ç½®

### 1. ç’°å¢ƒéœ€æ±‚
- Python 3.8+
- OpenAI API Key

### 2. å®‰è£æ­¥é©Ÿ

```bash
# 1. å…‹éš†æˆ–é€²å…¥å°ˆæ¡ˆç›®éŒ„
cd /home/jim/code/py/test_Time_RAG_stream

# 2. å®‰è£ä¾è³´
pip install -r requirements.txt

# 3. è¨­å®š OpenAI API Key
export OPENAI_API_KEY="your-api-key-here"

# æˆ–å‰µå»º .env æ–‡ä»¶
echo "OPENAI_API_KEY=your-api-key-here" > .env
```

### 3. ç›®éŒ„æº–å‚™

```bash
# å‰µå»ºå¿…è¦çš„ç›®éŒ„
mkdir -p docs scenarios results
```

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿé–‹å§‹

#### 1ï¸âƒ£ æº–å‚™æ•™ææ–‡ä»¶

åœ¨ `docs/` ç›®éŒ„ä¸‹æ”¾ç½® 3 ä»½æ•™ææ–‡ä»¶ï¼š

```bash
# ç¯„ä¾‹ï¼šå‰µå»ºæ¸¬è©¦æ•™æ
cat > docs/ml_basics.txt << 'EOF'
æ©Ÿå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºæ…§çš„ä¸€å€‹åˆ†æ”¯ï¼Œå®ƒä½¿è¨ˆç®—æ©Ÿèƒ½å¤ å¾æ•¸æ“šä¸­å­¸ç¿’ä¸¦æ”¹é€²æ€§èƒ½ã€‚
ä¸»è¦é¡å‹åŒ…æ‹¬ï¼š
1. ç›£ç£å¼å­¸ç¿’ - ä½¿ç”¨æ¨™è¨˜æ•¸æ“šè¨“ç·´æ¨¡å‹
2. éç›£ç£å¼å­¸ç¿’ - å¾æœªæ¨™è¨˜æ•¸æ“šä¸­ç™¼ç¾æ¨¡å¼
3. å¼·åŒ–å­¸ç¿’ - é€šéçå‹µæ©Ÿåˆ¶å­¸ç¿’æœ€ä½³ç­–ç•¥
EOF

cat > docs/deep_learning.txt << 'EOF'
æ·±åº¦å­¸ç¿’æ˜¯æ©Ÿå™¨å­¸ç¿’çš„å­é ˜åŸŸï¼Œä½¿ç”¨å¤šå±¤ç¥ç¶“ç¶²çµ¡è™•ç†è¤‡é›œæ•¸æ“šã€‚
é—œéµæ¦‚å¿µï¼š
- ç¥ç¶“ç¶²çµ¡æ¶æ§‹ï¼ˆCNNã€RNNã€Transformerï¼‰
- åå‘å‚³æ’­ç®—æ³•
- æ¢¯åº¦ä¸‹é™å„ªåŒ–
- æ­£å‰‡åŒ–æŠ€è¡“ï¼ˆDropoutã€Batch Normalizationï¼‰
EOF

cat > docs/nlp_intro.txt << 'EOF'
è‡ªç„¶èªè¨€è™•ç† (NLP) æ˜¯è®“è¨ˆç®—æ©Ÿç†è§£å’Œç”Ÿæˆäººé¡èªè¨€çš„æŠ€è¡“ã€‚
ä¸»è¦ä»»å‹™ï¼š
- æ–‡æœ¬åˆ†é¡
- å‘½åå¯¦é«”è­˜åˆ¥
- æ©Ÿå™¨ç¿»è­¯
- æƒ…æ„Ÿåˆ†æ
- å•ç­”ç³»çµ±
å¸¸ç”¨æ¨¡å‹ï¼šBERTã€GPTã€T5
EOF
```

#### 2ï¸âƒ£ æº–å‚™æƒ…å¢ƒæ–‡ä»¶

åœ¨ `scenarios/` ç›®éŒ„ä¸‹å‰µå»ºæƒ…å¢ƒæ–‡ä»¶ï¼š

```bash
# ç¯„ä¾‹ï¼šå‰µå»ºæƒ…å¢ƒ JSON
cat > scenarios/academic.json << 'EOF'
{
  "id": "academic",
  "name": "å­¸è¡“ç ”ç©¶æƒ…å¢ƒ",
  "dimensions": {
    "D1": 2,
    "D2": 4,
    "D3": 5,
    "D4": 2
  },
  "content": "é€™æ˜¯ä¸€å€‹å­¸è¡“ç ”ç©¶å ´æ™¯ï¼Œéœ€è¦æä¾›æ·±å…¥çš„æŠ€è¡“ç´°ç¯€å’Œå¼•ç”¨ä¾†æºã€‚å›ç­”æ‡‰è©²å°ˆæ¥­ã€åš´è¬¹ï¼ŒåŒ…å«ç›¸é—œç†è«–åŸºç¤ã€‚"
}
EOF

cat > scenarios/practical.json << 'EOF'
{
  "id": "practical",
  "name": "å¯¦å‹™æ‡‰ç”¨æƒ…å¢ƒ",
  "dimensions": {
    "D1": 4,
    "D2": 3,
    "D3": 3,
    "D4": 3
  },
  "content": "é€™æ˜¯ä¸€å€‹å¯¦å‹™æ‡‰ç”¨å ´æ™¯ï¼Œéœ€è¦æä¾›å¯æ“ä½œçš„æ­¥é©Ÿå’Œå¯¦éš›ç¯„ä¾‹ã€‚å›ç­”æ‡‰è©²ç°¡æ½”æ˜ç­ï¼Œæ³¨é‡å¯¦ç”¨æ€§ã€‚"
}
EOF

cat > scenarios/beginner.txt << 'EOF'
é€™æ˜¯ä¸€å€‹åˆå­¸è€…å­¸ç¿’æƒ…å¢ƒã€‚
ä½¿ç”¨è€…å¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡æ¥è§¸é€™å€‹ä¸»é¡Œï¼Œéœ€è¦ï¼š
- ç°¡å–®æ˜“æ‡‚çš„è§£é‡‹
- é¿å…éå¤šå°ˆæ¥­è¡“èª
- æä¾›é¡æ¯”å’Œå¯¦ä¾‹
- å¾ªåºæ¼¸é€²çš„èªªæ˜
EOF
```

#### 3ï¸âƒ£ åŸ·è¡Œç³»çµ±

```bash
# ç›´æ¥åŸ·è¡Œä¸»ç¨‹åº
python main.py
```

### è‡ªå®šç¾©ä½¿ç”¨

```python
import asyncio
from main import RAGStreamSystem

async def custom_usage():
    # åˆå§‹åŒ–ç³»çµ±
    system = RAGStreamSystem(api_key="your-api-key")
    
    # åˆå§‹åŒ–æ–‡ä»¶å’Œæƒ…å¢ƒ
    await system.initialize_documents("docs")
    await system.load_scenarios("scenarios")
    
    # è™•ç†å–®å€‹æŸ¥è©¢
    result = await system.process_query(
        query="ä»€éº¼æ˜¯æ·±åº¦å­¸ç¿’ï¼Ÿ",
        scenario_ids=["academic"],  # æŒ‡å®šæƒ…å¢ƒ
        auto_classify=False  # ä¸è‡ªå‹•åˆ†é¡
    )
    
    # æ‰“å°çµæœ
    system.print_summary(result)
    system.save_result(result)

# åŸ·è¡Œ
asyncio.run(custom_usage())
```

---

## ğŸ” æ¨¡çµ„è©³è§£

### 1. timer_utils.py - æ™‚é–“åˆ†ææ¨¡çµ„

#### æ ¸å¿ƒé¡åˆ¥

**TimerRecord**
```python
@dataclass
class TimerRecord:
    name: str           # éšæ®µåç¨±
    start_time: float   # é–‹å§‹æ™‚é–“
    end_time: float     # çµæŸæ™‚é–“
    duration: float     # æŒçºŒæ™‚é–“
```

**Timer**
```python
class Timer:
    def start_stage(stage_name: str)  # é–‹å§‹è¨ˆæ™‚
    def stop_stage(stage_name: str)   # åœæ­¢è¨ˆæ™‚
    def get_report() -> TimerReport   # ç”Ÿæˆå ±å‘Š
    def print_report()                # æ‰“å°å ±å‘Š
```

#### ä½¿ç”¨ç¯„ä¾‹

```python
from timer_utils import Timer

timer = Timer()

timer.start_stage("è³‡æ–™è™•ç†")
# ... åŸ·è¡Œä»»å‹™ ...
timer.stop_stage("è³‡æ–™è™•ç†")

timer.start_stage("æ¨¡å‹æ¨ç†")
# ... åŸ·è¡Œä»»å‹™ ...
timer.stop_stage("æ¨¡å‹æ¨ç†")

# ç”Ÿæˆå ±å‘Š
report = timer.get_report()
print(report.to_dict())
```

---

### 2. vector_store.py - å‘é‡å„²å­˜æ¨¡çµ„

#### æ ¸å¿ƒé¡åˆ¥

**VectorStore**
```python
class VectorStore:
    async def create_embedding(text: str) -> List[float]
    async def add_document(doc_id: str, content: str, metadata: dict)
    async def batch_add_documents(documents: List[Dict])
    def save()                        # å„²å­˜å‘é‡
    def load() -> bool                # è¼‰å…¥å‘é‡
    def export_to_json(json_path: str)
```

#### ä½¿ç”¨ç¯„ä¾‹

```python
from vector_store import VectorStore

# åˆå§‹åŒ–
store = VectorStore(storage_path="vectors.pkl")

# æ·»åŠ æ–‡ä»¶
await store.add_document(
    doc_id="doc1",
    content="é€™æ˜¯ä¸€ä»½é—œæ–¼æ©Ÿå™¨å­¸ç¿’çš„æ–‡ä»¶",
    metadata={"category": "ML"}
)

# å„²å­˜
store.save()

# è¼‰å…¥
store.load()
```

#### ç›¸ä¼¼åº¦è¨ˆç®—

```python
from vector_store import cosine_similarity

vec1 = [0.1, 0.2, 0.3, ...]
vec2 = [0.15, 0.25, 0.28, ...]

similarity = cosine_similarity(vec1, vec2)
print(f"ç›¸ä¼¼åº¦: {similarity:.3f}")
```

---

### 3. rag_module.py - RAG æª¢ç´¢æ¨¡çµ„

#### æ ¸å¿ƒé¡åˆ¥

**RAGRetriever**
```python
class RAGRetriever:
    async def retrieve(query: str, top_k: int) -> List[Dict]
    async def retrieve_with_threshold(query: str, threshold: float)
    def format_context(retrieved_docs: List[Dict]) -> str
    def get_matched_doc_ids(retrieved_docs: List[Dict]) -> List[str]
```

**RAGCache**
```python
class RAGCache:
    def get(query: str) -> List[Dict] | None
    def put(query: str, results: List[Dict])
    def get_stats() -> Dict
```

#### ä½¿ç”¨ç¯„ä¾‹

```python
from rag_module import RAGRetriever, RAGCache

# åˆå§‹åŒ–æª¢ç´¢å™¨
retriever = RAGRetriever(vector_store)

# æª¢ç´¢ç›¸é—œæ–‡ä»¶
results = await retriever.retrieve(
    query="ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
    top_k=3
)

# æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
context = retriever.format_context(results)

# ä½¿ç”¨å¿«å–
cache = RAGCache()
cached_results = cache.get(query)
if not cached_results:
    results = await retriever.retrieve(query)
    cache.put(query, results)
```

---

### 4. scenario_module.py - æƒ…å¢ƒåˆ¤å®šæ¨¡çµ„

#### æ ¸å¿ƒé¡åˆ¥

**ScenarioClassifier**
```python
class ScenarioClassifier:
    DIMENSIONS = {
        "D1": "æ™‚é–“æ•æ„Ÿæ€§",
        "D2": "æƒ…å¢ƒè¤‡é›œåº¦",
        "D3": "å°ˆæ¥­é ˜åŸŸ",
        "D4": "äº’å‹•æ¨¡å¼"
    }
    
    def load_scenarios_from_dir(scenarios_dir: str)
    async def classify_scenario(query: str, context: str) -> Dict
    def get_scenario_by_dimensions(classification: Dict) -> List[str]
    def get_scenario_content(scenario_id: str) -> str
```

**ScenarioInjector**
```python
class ScenarioInjector:
    def create_injection_prompt(
        draft_response: str,
        scenario_context: str,
        original_query: str
    ) -> str
```

#### å››å‘åº¦èªªæ˜

| å‘åº¦ | åç¨± | èªªæ˜ | è©•åˆ†æ¨™æº– (1-5) |
|------|------|------|----------------|
| **D1** | æ™‚é–“æ•æ„Ÿæ€§ | æ˜¯å¦éœ€è¦å³æ™‚å›æ‡‰ | 1=ä¸æ€¥ â†’ 5=æ¥µæ€¥ |
| **D2** | æƒ…å¢ƒè¤‡é›œåº¦ | å•é¡Œè¤‡é›œç¨‹åº¦ | 1=ç°¡å–® â†’ 5=è¤‡é›œ |
| **D3** | å°ˆæ¥­é ˜åŸŸ | å°ˆæ¥­çŸ¥è­˜éœ€æ±‚ | 1=é€šç”¨ â†’ 5=å°ˆæ¥­ |
| **D4** | äº’å‹•æ¨¡å¼ | äº’å‹•é¡å‹ | 1=å–®æ¬¡ â†’ 5=å¤šè¼ª |

#### ä½¿ç”¨ç¯„ä¾‹

```python
from scenario_module import ScenarioClassifier, ScenarioInjector

# åˆå§‹åŒ–åˆ†é¡å™¨
classifier = ScenarioClassifier()
classifier.load_scenarios_from_dir("scenarios")

# åˆ†é¡æƒ…å¢ƒ
classification = await classifier.classify_scenario(
    query="å¦‚ä½•å„ªåŒ–æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Ÿ",
    context="ç›¸é—œæŠ€è¡“æ–‡ä»¶..."
)

# çµæœç¯„ä¾‹
{
  "D1": {"score": 2, "reason": "éç·Šæ€¥å•é¡Œ"},
  "D2": {"score": 4, "reason": "éœ€è¦æ·±å…¥æŠ€è¡“ç†è§£"},
  "D3": {"score": 5, "reason": "å°ˆæ¥­æ·±åº¦å­¸ç¿’çŸ¥è­˜"},
  "D4": {"score": 3, "reason": "å¯èƒ½éœ€è¦å¤šè¼ªå°è©±"}
}

# ç²å–æ¨è–¦æƒ…å¢ƒ
scenarios = classifier.get_scenario_by_dimensions(classification)
```

---

### 5. main.py - ä¸»ç¨‹åº

#### æ ¸å¿ƒé¡åˆ¥

**RAGStreamSystem**
```python
class RAGStreamSystem:
    async def initialize_documents(docs_dir: str)
    async def load_scenarios(scenarios_dir: str)
    async def generate_draft(query: str, context: str) -> str
    async def resume_with_scenario(query: str, scenario_ids: List[str]) -> str
    async def process_query(query: str, scenario_ids: List[str]) -> Dict
    async def run_background_tasks()
    def save_result(result: Dict, output_dir: str)
    def print_summary(result: Dict)
```

#### å®Œæ•´æµç¨‹

```python
async def main():
    # 1. åˆå§‹åŒ–ç³»çµ±
    system = RAGStreamSystem()
    
    # 2. åˆå§‹åŒ–æ–‡ä»¶å’Œæƒ…å¢ƒ
    await system.initialize_documents()
    await system.load_scenarios()
    
    # 3. è™•ç†æŸ¥è©¢
    result = await system.process_query("ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ")
    
    # 4. è¼¸å‡ºçµæœ
    system.print_summary(result)
    system.save_result(result)
```

---

## ğŸ”„ å·¥ä½œæµç¨‹

### å®Œæ•´åŸ·è¡Œæµç¨‹åœ–

```
é–‹å§‹
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: åˆå§‹åŒ–æ–‡ä»¶  â”‚
â”‚ - æª¢æŸ¥ vectors.pkl  â”‚
â”‚ - è‹¥ç„¡å‰‡å‘é‡åŒ–      â”‚
â”‚ - å„²å­˜å‘é‡          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: è¼‰å…¥æƒ…å¢ƒ    â”‚
â”‚ - è®€å– scenarios/   â”‚
â”‚ - è§£æ JSON/TXT     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: RAG æª¢ç´¢    â”‚
â”‚ - ç”ŸæˆæŸ¥è©¢å‘é‡      â”‚
â”‚ - è¨ˆç®—ç›¸ä¼¼åº¦        â”‚
â”‚ - è¿”å› Top-K        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: æƒ…å¢ƒåˆ†é¡    â”‚
â”‚ - å››å‘åº¦è©•åˆ†        â”‚
â”‚ - æ¨è–¦æƒ…å¢ƒ          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5: ç”Ÿæˆè‰ç¨¿    â”‚
â”‚ - åŸºæ–¼ RAG ä¸Šä¸‹æ–‡   â”‚
â”‚ - æš«å­˜ä¸è¼¸å‡º        â”‚
â”‚ - æ¨¡æ“¬ Stream Pause â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 6: æƒ…å¢ƒæ³¨å…¥    â”‚
â”‚ - æ³¨å…¥æƒ…å¢ƒä¸Šä¸‹æ–‡    â”‚
â”‚ - Resume Stream     â”‚
â”‚ - ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 7: èƒŒæ™¯ä»»å‹™    â”‚
â”‚ - é¡è‰²æ¨™ç±¤æ›´æ–°      â”‚
â”‚ - å¿«å–æ¨™è¨»å„²å­˜      â”‚
â”‚ - æ´»å‹•æ—¥èªŒè¨˜éŒ„      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 8: è¼¸å‡ºçµæœ    â”‚
â”‚ - ç”Ÿæˆæ™‚é–“å ±å‘Š      â”‚
â”‚ - å„²å­˜ JSON         â”‚
â”‚ - æ‰“å°æ‘˜è¦          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
çµæŸ
```

### æ™‚é–“ç·šåˆ†æ

```
æ™‚é–“è»¸ (ç§’)
0.0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> 6.2
â”‚         â”‚        â”‚       â”‚        â”‚          â”‚        â”‚
â”‚ å‘é‡åŒ–  â”‚ RAG    â”‚ æƒ…å¢ƒ  â”‚ è‰ç¨¿   â”‚ çºŒå¯«     â”‚ èƒŒæ™¯   â”‚
â”‚ 0.5s    â”‚ 0.7s   â”‚ 0.8s  â”‚ 1.2s   â”‚ 2.5s     â”‚ 0.5s   â”‚
â”‚         â”‚        â”‚       â”‚        â”‚          â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  åˆå§‹åŒ–    æª¢ç´¢     åˆ†é¡    æš«åœ     æ³¨å…¥       ä»»å‹™
```

---

## ğŸ§ª æ¸¬è©¦èˆ‡é©—è­‰

### å–®å…ƒæ¸¬è©¦ç¯„ä¾‹

å‰µå»º `test_system.py`ï¼š

```python
import asyncio
import pytest
from main import RAGStreamSystem

@pytest.mark.asyncio
async def test_vector_store():
    """æ¸¬è©¦å‘é‡å„²å­˜åŠŸèƒ½"""
    system = RAGStreamSystem()
    
    # æ¸¬è©¦å‘é‡åŒ–
    await system.vector_store.add_document(
        doc_id="test_doc",
        content="æ¸¬è©¦æ–‡ä»¶å…§å®¹"
    )
    
    # é©—è­‰å„²å­˜
    assert "test_doc" in system.vector_store.get_all_documents()
    
    # æ¸¬è©¦å„²å­˜èˆ‡è¼‰å…¥
    system.vector_store.save()
    system.vector_store.clear()
    assert system.vector_store.load() == True

@pytest.mark.asyncio
async def test_rag_retrieval():
    """æ¸¬è©¦ RAG æª¢ç´¢åŠŸèƒ½"""
    system = RAGStreamSystem()
    await system.initialize_documents()
    
    # æ¸¬è©¦æª¢ç´¢
    results = await system.rag_retriever.retrieve(
        query="æ©Ÿå™¨å­¸ç¿’",
        top_k=3
    )
    
    assert len(results) <= 3
    assert all("score" in r for r in results)

@pytest.mark.asyncio
async def test_full_pipeline():
    """æ¸¬è©¦å®Œæ•´æµç¨‹"""
    system = RAGStreamSystem()
    await system.initialize_documents()
    await system.load_scenarios()
    
    result = await system.process_query("ä»€éº¼æ˜¯æ·±åº¦å­¸ç¿’ï¼Ÿ")
    
    assert "final_answer" in result
    assert "time_report" in result
    assert result["time_report"]["total_time"] > 0
```

### åŸ·è¡Œæ¸¬è©¦

```bash
# å®‰è£ pytest
pip install pytest pytest-asyncio

# åŸ·è¡Œæ¸¬è©¦
pytest test_system.py -v
```

### æ‰‹å‹•æ¸¬è©¦è…³æœ¬

å‰µå»º `manual_test.py`ï¼š

```python
import asyncio
from main import RAGStreamSystem

async def manual_test():
    """æ‰‹å‹•æ¸¬è©¦è…³æœ¬"""
    
    print("ğŸ§ª é–‹å§‹æ‰‹å‹•æ¸¬è©¦...")
    
    # åˆå§‹åŒ–
    system = RAGStreamSystem()
    await system.initialize_documents()
    await system.load_scenarios()
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        {
            "query": "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
            "expected_docs": ["ml_basics.txt"],
            "expected_scenario": ["beginner"]
        },
        {
            "query": "å¦‚ä½•å„ªåŒ–æ·±åº¦å­¸ç¿’æ¨¡å‹çš„è¨“ç·´é€Ÿåº¦ï¼Ÿ",
            "expected_docs": ["deep_learning.txt"],
            "expected_scenario": ["practical", "academic"]
        },
        {
            "query": "BERT æ¨¡å‹åœ¨ NLP ä¸­çš„æ‡‰ç”¨",
            "expected_docs": ["nlp_intro.txt"],
            "expected_scenario": ["academic"]
        }
    ]
    
    results = []
    for i, case in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"æ¸¬è©¦æ¡ˆä¾‹ {i}: {case['query']}")
        print(f"{'='*60}")
        
        result = await system.process_query(case["query"])
        results.append(result)
        
        # é©—è­‰çµæœ
        print(f"\nâœ… é©—è­‰:")
        print(f"  åŒ¹é…æ–‡ä»¶: {result['matched_docs']}")
        print(f"  ä½¿ç”¨æƒ…å¢ƒ: {result['scenario_used']}")
        print(f"  ç¸½è€—æ™‚: {result['time_report']['total_time']}s")
        
        system.save_result(result)
    
    # çµ±è¨ˆåˆ†æ
    print(f"\n{'='*60}")
    print("ğŸ“Š æ¸¬è©¦çµ±è¨ˆ")
    print(f"{'='*60}")
    
    avg_time = sum(r['time_report']['total_time'] for r in results) / len(results)
    print(f"å¹³å‡è€—æ™‚: {avg_time:.3f}s")
    
    print("\nâœ… æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(manual_test())
```

---

## ğŸ“Š æ•ˆèƒ½åˆ†æ

### æ™‚é–“åˆ†æå ±å‘Šæ ¼å¼

```json
{
  "timestamp": "2025-10-08T12:26:38+08:00",
  "stages": {
    "å‘é‡åŒ–": 0.523,
    "RAGæª¢ç´¢": 0.718,
    "æƒ…å¢ƒåˆ†é¡": 0.842,
    "LLMè‰ç¨¿ç”Ÿæˆ": 1.234,
    "æƒ…å¢ƒæ³¨å…¥èˆ‡çºŒå¯«": 2.567,
    "èƒŒæ™¯ä»»å‹™": 0.456
  },
  "total_time": 6.340
}
```

### æ•ˆèƒ½å„ªåŒ–å»ºè­°

#### 1. å‘é‡å¿«å–
```python
# ä½¿ç”¨å·²å„²å­˜çš„å‘é‡ï¼Œé¿å…é‡è¤‡è¨ˆç®—
if vector_store.load():
    print("âœ… ä½¿ç”¨å¿«å–å‘é‡")
else:
    await vector_store.batch_add_documents(docs)
    vector_store.save()
```

#### 2. RAG å¿«å–
```python
# å¿«å–æª¢ç´¢çµæœ
cache = RAGCache(max_size=100)
results = cache.get(query)
if not results:
    results = await retriever.retrieve(query)
    cache.put(query, results)
```

#### 3. ä¸¦è¡Œè™•ç†
```python
# ä¸¦è¡ŒåŸ·è¡Œç¨ç«‹ä»»å‹™
results = await asyncio.gather(
    rag_retriever.retrieve(query),
    scenario_classifier.classify_scenario(query),
    background_task_1(),
    background_task_2()
)
```

#### 4. æ¨¡å‹é¸æ“‡
```python
# ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹åŠ é€Ÿ
classifier = ScenarioClassifier(use_small_model=True)  # gpt-3.5-turbo
```

### æ•ˆèƒ½åŸºæº–

| éšæ®µ | é æœŸè€—æ™‚ | å„ªåŒ–ç›®æ¨™ |
|------|----------|----------|
| å‘é‡åŒ– (é¦–æ¬¡) | 2-5s | ä½¿ç”¨å¿«å– â†’ <0.1s |
| RAG æª¢ç´¢ | 0.5-1s | ä½¿ç”¨å¿«å– â†’ <0.1s |
| æƒ…å¢ƒåˆ†é¡ | 0.8-1.5s | ä½¿ç”¨å°æ¨¡å‹ |
| LLM è‰ç¨¿ | 1-2s | æ¸›å°‘ max_tokens |
| æƒ…å¢ƒçºŒå¯« | 2-4s | æµå¼è¼¸å‡º |
| èƒŒæ™¯ä»»å‹™ | 0.3-0.6s | ä¸¦è¡ŒåŸ·è¡Œ |
| **ç¸½è¨ˆ** | **6-10s** | **<5s** |

---

## â“ å¸¸è¦‹å•é¡Œ

### Q1: å¦‚ä½•è¨­å®š OpenAI API Keyï¼Ÿ

**æ–¹æ³• 1: ç’°å¢ƒè®Šé‡**
```bash
export OPENAI_API_KEY="sk-..."
```

**æ–¹æ³• 2: .env æ–‡ä»¶**
```bash
echo "OPENAI_API_KEY=sk-..." > .env
pip install python-dotenv
```

**æ–¹æ³• 3: ä»£ç¢¼ä¸­è¨­å®š**
```python
system = RAGStreamSystem(api_key="sk-...")
```

### Q2: å‘é‡æ–‡ä»¶å¤ªå¤§æ€éº¼è¾¦ï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆï¼š**
1. ä½¿ç”¨è¼ƒå°çš„ embedding æ¨¡å‹
2. åˆ†æ‰¹è™•ç†æ–‡ä»¶
3. ä½¿ç”¨å‘é‡è³‡æ–™åº« (å¦‚ Pinecone, Weaviate)

```python
# åˆ†æ‰¹è™•ç†
batch_size = 10
for i in range(0, len(documents), batch_size):
    batch = documents[i:i+batch_size]
    await vector_store.batch_add_documents(batch)
    vector_store.save()
```

### Q3: å¦‚ä½•è‡ªå®šç¾©æƒ…å¢ƒå‘åº¦ï¼Ÿ

**ä¿®æ”¹ `scenario_module.py`ï¼š**
```python
class ScenarioClassifier:
    DIMENSIONS = {
        "D1": "è‡ªå®šç¾©å‘åº¦1",
        "D2": "è‡ªå®šç¾©å‘åº¦2",
        "D3": "è‡ªå®šç¾©å‘åº¦3",
        "D4": "è‡ªå®šç¾©å‘åº¦4",
        "D5": "æ–°å¢å‘åº¦5"  # å¯æ“´å±•
    }
```

### Q4: å¦‚ä½•è™•ç†å¤§é‡æ–‡ä»¶ï¼Ÿ

**ä½¿ç”¨å¢é‡æ›´æ–°ï¼š**
```python
# åªå‘é‡åŒ–æ–°æ–‡ä»¶
existing_docs = vector_store.get_all_documents()
new_docs = [d for d in documents if d["id"] not in existing_docs]

if new_docs:
    await vector_store.batch_add_documents(new_docs)
    vector_store.save()
```

### Q5: å¦‚ä½•èª¿æ•´æª¢ç´¢ç²¾åº¦ï¼Ÿ

**èª¿æ•´åƒæ•¸ï¼š**
```python
# å¢åŠ  top_k
results = await retriever.retrieve(query, top_k=5)

# ä½¿ç”¨ç›¸ä¼¼åº¦é–¾å€¼
results = await retriever.retrieve_with_threshold(
    query=query,
    threshold=0.75,  # åªè¿”å›ç›¸ä¼¼åº¦ > 0.75 çš„æ–‡ä»¶
    top_k=10
)
```

### Q6: å¦‚ä½•æ¸›å°‘ API èª¿ç”¨æˆæœ¬ï¼Ÿ

**å„ªåŒ–ç­–ç•¥ï¼š**
1. ä½¿ç”¨å¿«å–æ©Ÿåˆ¶
2. é¸æ“‡è¼ƒå°çš„æ¨¡å‹
3. æ¸›å°‘ max_tokens
4. æ‰¹é‡è™•ç†è«‹æ±‚

```python
# ä½¿ç”¨ gpt-3.5-turbo æ›¿ä»£ gpt-4
classifier = ScenarioClassifier(use_small_model=True)

# æ¸›å°‘è¼¸å‡ºé•·åº¦
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    max_tokens=300  # æ¸›å°‘ token ä½¿ç”¨
)
```

---

## ğŸš€ é€²éšåŠŸèƒ½

### 1. è‡ªå®šç¾©å‘é‡æ¨¡å‹

```python
class CustomVectorStore(VectorStore):
    def __init__(self, model_name="text-embedding-3-large"):
        super().__init__()
        self.embedding_model = model_name  # ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
```

### 2. å¤šèªè¨€æ”¯æ´

```python
async def multilingual_retrieve(query: str, language: str = "zh"):
    """æ”¯æ´å¤šèªè¨€æª¢ç´¢"""
    if language != "zh":
        # ç¿»è­¯æŸ¥è©¢
        query = await translate(query, target_lang="zh")
    
    results = await retriever.retrieve(query)
    return results
```

### 3. æµå¼è¼¸å‡ºå„ªåŒ–

```python
async def stream_with_callback(query: str, callback):
    """å¸¶å›èª¿çš„æµå¼è¼¸å‡º"""
    stream = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[...],
        stream=True
    )
    
    for chunk in stream:
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            await callback(content)  # å¯¦æ™‚å›èª¿
```

### 4. åˆ†æ•£å¼å‘é‡å„²å­˜

```python
# æ•´åˆ Pinecone
import pinecone

class PineconeVectorStore(VectorStore):
    def __init__(self, index_name: str):
        pinecone.init(api_key="...")
        self.index = pinecone.Index(index_name)
    
    async def add_document(self, doc_id: str, content: str):
        embedding = await self.create_embedding(content)
        self.index.upsert([(doc_id, embedding, {"content": content})])
```

### 5. å¯¦æ™‚ç›£æ§

```python
class MonitoredRAGSystem(RAGStreamSystem):
    def __init__(self):
        super().__init__()
        self.metrics = {
            "total_queries": 0,
            "avg_response_time": 0,
            "cache_hit_rate": 0
        }
    
    async def process_query(self, query: str):
        self.metrics["total_queries"] += 1
        result = await super().process_query(query)
        
        # æ›´æ–°æŒ‡æ¨™
        self.update_metrics(result)
        return result
```

---

## ğŸ“ çµèª

é€™å€‹ç³»çµ±æä¾›äº†ä¸€å€‹**æœ€å°å¯è¡Œçš„ RAG æµå¼ä¸­æ–·èˆ‡çºŒå¯«**å¯¦ç¾ï¼Œå…·å‚™ä»¥ä¸‹å„ªå‹¢ï¼š

âœ… **æ¨¡çµ„åŒ–è¨­è¨ˆ**ï¼šæ¯å€‹æ¨¡çµ„è·è²¬æ¸…æ™°ï¼Œæ˜“æ–¼æ“´å±•  
âœ… **ç²¾æº–è¨ˆæ™‚**ï¼šè©³ç´°çš„æ™‚é–“åˆ†æï¼Œä¾¿æ–¼æ•ˆèƒ½å„ªåŒ–  
âœ… **å¯é‡è¤‡æ¸¬è©¦**ï¼šæ”¯æ´å¿«å–èˆ‡å¢é‡æ›´æ–°  
âœ… **éˆæ´»é…ç½®**ï¼šæ”¯æ´è‡ªå®šç¾©æƒ…å¢ƒã€å‘åº¦å’Œåƒæ•¸  
âœ… **ç”Ÿç”¢å°±ç·’**ï¼šå®Œæ•´çš„éŒ¯èª¤è™•ç†å’Œæ—¥èªŒè¨˜éŒ„  

### ä¸‹ä¸€æ­¥å»ºè­°

1. **æ•´åˆå‘é‡è³‡æ–™åº«**ï¼šä½¿ç”¨ Pineconeã€Weaviate æˆ– Qdrant
2. **æ·»åŠ  Web ç•Œé¢**ï¼šä½¿ç”¨ Streamlit æˆ– Gradio
3. **å¯¦ç¾ç”¨æˆ¶åé¥‹**ï¼šæ”¶é›†ä¸¦å„ªåŒ–å›ç­”è³ªé‡
4. **éƒ¨ç½²åˆ°é›²ç«¯**ï¼šä½¿ç”¨ Docker + Kubernetes
5. **ç›£æ§èˆ‡å‘Šè­¦**ï¼šæ•´åˆ Prometheus + Grafana

### è¯ç¹«èˆ‡æ”¯æ´

- **ä½œè€…**: Jim
- **ç‰ˆæœ¬**: 1.0.0
- **æ›´æ–°æ—¥æœŸ**: 2025-10-08

---

**Happy Coding! ğŸš€**
